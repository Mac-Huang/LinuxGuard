[
  {
    "sha": "a5aa7bc1fca78c7fa127d9e33aa94a0c9066c1d6",
    "message": "drm/i915/gt: Fix timeline left held on VMA alloc error\n\nThe following error has been reported sporadically by CI when a test\nunbinds the i915 driver on a ring submission platform:\n\n<4> [239.330153] ------------[ cut here ]------------\n<4> [239.330166] i915 0000:00:02.0: [drm] drm_WARN_ON(dev_priv->mm.shrink_count)\n<4> [239.330196] WARNING: CPU: 1 PID: 18570 at drivers/gpu/drm/i915/i915_gem.c:1309 i915_gem_cleanup_early+0x13e/0x150 [i915]\n...\n<4> [239.330640] RIP: 0010:i915_gem_cleanup_early+0x13e/0x150 [i915]\n...\n<4> [239.330942] Call Trace:\n<4> [239.330944]  <TASK>\n<4> [239.330949]  i915_driver_late_release+0x2b/0xa0 [i915]\n<4> [239.331202]  i915_driver_release+0x86/0xa0 [i915]\n<4> [239.331482]  devm_drm_dev_init_release+0x61/0x90\n<4> [239.331494]  devm_action_release+0x15/0x30\n<4> [239.331504]  release_nodes+0x3d/0x120\n<4> [239.331517]  devres_release_all+0x96/0xd0\n<4> [239.331533]  device_unbind_cleanup+0x12/0x80\n<4> [239.331543]  device_release_driver_internal+0x23a/0x280\n<4> [239.331550]  ? bus_find_device+0xa5/0xe0\n<4> [239.331563]  device_driver_detach+0x14/0x20\n...\n<4> [357.719679] ---[ end trace 0000000000000000 ]---\n\nIf the test also unloads the i915 module then that's followed with:\n\n<3> [357.787478] =============================================================================\n<3> [357.788006] BUG i915_vma (Tainted: G     U  W        N ): Objects remaining on __kmem_cache_shutdown()\n<3> [357.788031] -----------------------------------------------------------------------------\n<3> [357.788204] Object 0xffff888109e7f480 @offset=29824\n<3> [357.788670] Allocated in i915_vma_instance+0xee/0xc10 [i915] age=292729 cpu=4 pid=2244\n<4> [357.788994]  i915_vma_instance+0xee/0xc10 [i915]\n<4> [357.789290]  init_status_page+0x7b/0x420 [i915]\n<4> [357.789532]  intel_engines_init+0x1d8/0x980 [i915]\n<4> [357.789772]  intel_gt_init+0x175/0x450 [i915]\n<4> [357.790014]  i915_gem_init+0x113/0x340 [i915]\n<4> [357.790281]  i915_driver_probe+0x847/0xed0 [i915]\n<4> [357.790504]  i915_pci_probe+0xe6/0x220 [i915]\n...\n\nCloser analysis of CI results history has revealed a dependency of the\nerror on a few IGT tests, namely:\n- igt@api_intel_allocator@fork-simple-stress-signal,\n- igt@api_intel_allocator@two-level-inception-interruptible,\n- igt@gem_linear_blits@interruptible,\n- igt@prime_mmap_coherency@ioctl-errors,\nwhich invisibly trigger the issue, then exhibited with first driver unbind\nattempt.\n\nAll of the above tests perform actions which are actively interrupted with\nsignals.  Further debugging has allowed to narrow that scope down to\nDRM_IOCTL_I915_GEM_EXECBUFFER2, and ring_context_alloc(), specific to ring\nsubmission, in particular.\n\nIf successful then that function, or its execlists or GuC submission\nequivalent, is supposed to be called only once per GEM context engine,\nfollowed by raise of a flag that prevents the function from being called\nagain.  The function is expected to unwind its internal errors itself, so\nit may be safely called once more after it returns an error.\n\nIn case of ring submission, the function first gets a reference to the\nengine's legacy timeline and then allocates a VMA.  If the VMA allocation\nfails, e.g. when i915_vma_instance() called from inside is interrupted\nwith a signal, then ring_context_alloc() fails, leaving the timeline held\nreferenced.  On next I915_GEM_EXECBUFFER2 IOCTL, another reference to the\ntimeline is got, and only that last one is put on successful completion.\nAs a consequence, the legacy timeline, with its underlying engine status\npage's VMA object, is still held and not released on driver unbind.\n\nGet the legacy timeline only after successful allocation of the context\nengine's VMA.\n\nv2: Add a note on other submission methods (Krzysztof Karas):\n    Both execlists and GuC submission use lrc_alloc() which seems free\n    from a similar issue.\n\nFixes: 75d0a7f31eec (\"drm/i915: Lift timeline into intel_context\")\nCloses: https://gitlab.freedesktop.org/drm/i915/kernel/-/issues/12061\nCc: Chris Wilson <chris.p.wilson@linux.intel.com>\nCc: Matthew Auld <matthew.auld@intel.com>\nCc: Krzysztof Karas <krzysztof.karas@intel.com>\nReviewed-by: Sebastian Brzezinka <sebastian.brzezinka@intel.com>\nReviewed-by: Krzysztof Niemiec <krzysztof.niemiec@intel.com>\nSigned-off-by: Janusz Krzysztofik <janusz.krzysztofik@linux.intel.com>\nReviewed-by: Nitin Gote <nitin.r.gote@intel.com>\nReviewed-by: Andi Shyti <andi.shyti@linux.intel.com>\nSigned-off-by: Andi Shyti <andi.shyti@linux.intel.com>\nLink: https://lore.kernel.org/r/20250611104352.1014011-2-janusz.krzysztofik@linux.intel.com\n(cherry picked from commit cc43422b3cc79eacff4c5a8ba0d224688ca9dd4f)\nSigned-off-by: Joonas Lahtinen <joonas.lahtinen@linux.intel.com>",
    "author": "Janusz Krzysztofik",
    "date": "2025-07-01T08:10:42+03:00",
    "files_changed": [
      "drivers/gpu/drm/i915/gt/intel_ring_submission.c"
    ],
    "diff": "diff --git a/drivers/gpu/drm/i915/gt/intel_ring_submission.c b/drivers/gpu/drm/i915/gt/intel_ring_submission.c\nindex a876a34455f1..2a6d79abf25b 100644\n--- a/drivers/gpu/drm/i915/gt/intel_ring_submission.c\n+++ b/drivers/gpu/drm/i915/gt/intel_ring_submission.c\n@@ -610,7 +610,6 @@ static int ring_context_alloc(struct intel_context *ce)\n \t/* One ringbuffer to rule them all */\n \tGEM_BUG_ON(!engine->legacy.ring);\n \tce->ring = engine->legacy.ring;\n-\tce->timeline = intel_timeline_get(engine->legacy.timeline);\n \n \tGEM_BUG_ON(ce->state);\n \tif (engine->context_size) {\n@@ -623,6 +622,8 @@ static int ring_context_alloc(struct intel_context *ce)\n \t\tce->state = vma;\n \t}\n \n+\tce->timeline = intel_timeline_get(engine->legacy.timeline);\n+\n \treturn 0;\n }\n ",
    "stats": {
      "insertions": 2,
      "deletions": 1,
      "files": 1
    }
  },
  {
    "sha": "e39ed71c7a26e8e94c637e222bc373b511ca127f",
    "message": "net: txgbe: fix the issue of TX failure\n\nThere is a occasional problem that ping is failed between AML devices.\nThat is because the manual enablement of the security Tx path on the\nhardware is missing, no matter what its previous state was.\n\nFixes: 6f8b4c01a8cd (\"net: txgbe: Implement PHYLINK for AML 25G/10G devices\")\nSigned-off-by: Jiawen Wu <jiawenwu@trustnetic.com>\nReviewed-by: Simon Horman <horms@kernel.org>\nLink: https://patch.msgid.link/5BDFB14C57D1C42A+20250626085153.86122-1-jiawenwu@trustnetic.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>",
    "author": "Jiawen Wu",
    "date": "2025-06-30T18:15:53-07:00",
    "files_changed": [
      "drivers/net/ethernet/wangxun/txgbe/txgbe_aml.c"
    ],
    "diff": "diff --git a/drivers/net/ethernet/wangxun/txgbe/txgbe_aml.c b/drivers/net/ethernet/wangxun/txgbe/txgbe_aml.c\nindex 7dbcf41750c1..dc87ccad9652 100644\n--- a/drivers/net/ethernet/wangxun/txgbe/txgbe_aml.c\n+++ b/drivers/net/ethernet/wangxun/txgbe/txgbe_aml.c\n@@ -294,6 +294,7 @@ static void txgbe_mac_link_up_aml(struct phylink_config *config,\n \twx_fc_enable(wx, tx_pause, rx_pause);\n \n \ttxgbe_reconfig_mac(wx);\n+\ttxgbe_enable_sec_tx_path(wx);\n \n \ttxcfg = rd32(wx, TXGBE_AML_MAC_TX_CFG);\n \ttxcfg &= ~TXGBE_AML_MAC_TX_CFG_SPEED_MASK;",
    "stats": {
      "insertions": 1,
      "deletions": 0,
      "files": 1
    }
  },
  {
    "sha": "f3e58d8e154dae5015c7400812c80789589fc36e",
    "message": "drm/amdgpu: Fix memory leak in amdgpu_ctx_mgr_entity_fini\n\npatch dd64956685fa (\"drm/amdgpu: Remove duplicated \"context still\nalive\" check\") removed ctx put, which will cause amdgpu_ctx_fini()\ncannot be called and then cause some finished fence that added by\namdgpu_ctx_add_fence() cannot be released and cause memleak.\n\nFixes: dd64956685fa (\"drm/amdgpu: Remove duplicated \"context still alive\" check\")\nSigned-off-by: Lin.Cao <lincao12@amd.com>\nReviewed-by: Tvrtko Ursulin <tvrtko.ursulin@igalia.com>\nAcked-by: Christian KÃ¶nig <christian.koenig@amd.com>\nSigned-off-by: Alex Deucher <alexander.deucher@amd.com>\n(cherry picked from commit 8cf66089e28108dedd47e6156a48489303cf525c)\nCc: stable@vger.kernel.org",
    "author": "Lin.Cao",
    "date": "2025-06-30T13:57:31-04:00",
    "files_changed": [
      "drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c"
    ],
    "diff": "diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c\nindex 85567d0d9545..f5d5c45ddc0d 100644\n--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c\n+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c\n@@ -944,6 +944,7 @@ static void amdgpu_ctx_mgr_entity_fini(struct amdgpu_ctx_mgr *mgr)\n \t\t\t\tdrm_sched_entity_fini(entity);\n \t\t\t}\n \t\t}\n+\t\tkref_put(&ctx->refcount, amdgpu_ctx_fini);\n \t}\n }\n ",
    "stats": {
      "insertions": 1,
      "deletions": 0,
      "files": 1
    }
  },
  {
    "sha": "cf234231fcbc7d391e2135b9518613218cc5347f",
    "message": "drm/amdkfd: Don't call mmput from MMU notifier callback\n\nIf the process is exiting, the mmput inside mmu notifier callback from\ncompactd or fork or numa balancing could release the last reference\nof mm struct to call exit_mmap and free_pgtable, this triggers deadlock\nwith below backtrace.\n\nThe deadlock will leak kfd process as mmu notifier release is not called\nand cause VRAM leaking.\n\nThe fix is to take mm reference mmget_non_zero when adding prange to the\ndeferred list to pair with mmput in deferred list work.\n\nIf prange split and add into pchild list, the pchild work_item.mm is not\nused, so remove the mm parameter from svm_range_unmap_split and\nsvm_range_add_child.\n\nThe backtrace of hung task:\n\n INFO: task python:348105 blocked for more than 64512 seconds.\n Call Trace:\n  __schedule+0x1c3/0x550\n  schedule+0x46/0xb0\n  rwsem_down_write_slowpath+0x24b/0x4c0\n  unlink_anon_vmas+0xb1/0x1c0\n  free_pgtables+0xa9/0x130\n  exit_mmap+0xbc/0x1a0\n  mmput+0x5a/0x140\n  svm_range_cpu_invalidate_pagetables+0x2b/0x40 [amdgpu]\n  mn_itree_invalidate+0x72/0xc0\n  __mmu_notifier_invalidate_range_start+0x48/0x60\n  try_to_unmap_one+0x10fa/0x1400\n  rmap_walk_anon+0x196/0x460\n  try_to_unmap+0xbb/0x210\n  migrate_page_unmap+0x54d/0x7e0\n  migrate_pages_batch+0x1c3/0xae0\n  migrate_pages_sync+0x98/0x240\n  migrate_pages+0x25c/0x520\n  compact_zone+0x29d/0x590\n  compact_zone_order+0xb6/0xf0\n  try_to_compact_pages+0xbe/0x220\n  __alloc_pages_direct_compact+0x96/0x1a0\n  __alloc_pages_slowpath+0x410/0x930\n  __alloc_pages_nodemask+0x3a9/0x3e0\n  do_huge_pmd_anonymous_page+0xd7/0x3e0\n  __handle_mm_fault+0x5e3/0x5f0\n  handle_mm_fault+0xf7/0x2e0\n  hmm_vma_fault.isra.0+0x4d/0xa0\n  walk_pmd_range.isra.0+0xa8/0x310\n  walk_pud_range+0x167/0x240\n  walk_pgd_range+0x55/0x100\n  __walk_page_range+0x87/0x90\n  walk_page_range+0xf6/0x160\n  hmm_range_fault+0x4f/0x90\n  amdgpu_hmm_range_get_pages+0x123/0x230 [amdgpu]\n  amdgpu_ttm_tt_get_user_pages+0xb1/0x150 [amdgpu]\n  init_user_pages+0xb1/0x2a0 [amdgpu]\n  amdgpu_amdkfd_gpuvm_alloc_memory_of_gpu+0x543/0x7d0 [amdgpu]\n  kfd_ioctl_alloc_memory_of_gpu+0x24c/0x4e0 [amdgpu]\n  kfd_ioctl+0x29d/0x500 [amdgpu]\n\nFixes: fa582c6f3684 (\"drm/amdkfd: Use mmget_not_zero in MMU notifier\")\nSigned-off-by: Philip Yang <Philip.Yang@amd.com>\nReviewed-by: Felix Kuehling <felix.kuehling@amd.com>\nSigned-off-by: Alex Deucher <alexander.deucher@amd.com>\n(cherry picked from commit a29e067bd38946f752b0ef855f3dfff87e77bec7)\nCc: stable@vger.kernel.org",
    "author": "Philip Yang",
    "date": "2025-06-30T13:57:12-04:00",
    "files_changed": [
      "drivers/gpu/drm/amd/amdkfd/kfd_svm.c"
    ],
    "diff": "diff --git a/drivers/gpu/drm/amd/amdkfd/kfd_svm.c b/drivers/gpu/drm/amd/amdkfd/kfd_svm.c\nindex 7763e4742080..a0f22ea6d15a 100644\n--- a/drivers/gpu/drm/amd/amdkfd/kfd_svm.c\n+++ b/drivers/gpu/drm/amd/amdkfd/kfd_svm.c\n@@ -1171,13 +1171,12 @@ svm_range_split_head(struct svm_range *prange, uint64_t new_start,\n }\n \n static void\n-svm_range_add_child(struct svm_range *prange, struct mm_struct *mm,\n-\t\t    struct svm_range *pchild, enum svm_work_list_ops op)\n+svm_range_add_child(struct svm_range *prange, struct svm_range *pchild, enum svm_work_list_ops op)\n {\n \tpr_debug(\"add child 0x%p [0x%lx 0x%lx] to prange 0x%p child list %d\\n\",\n \t\t pchild, pchild->start, pchild->last, prange, op);\n \n-\tpchild->work_item.mm = mm;\n+\tpchild->work_item.mm = NULL;\n \tpchild->work_item.op = op;\n \tlist_add_tail(&pchild->child_list, &prange->child_list);\n }\n@@ -2394,15 +2393,17 @@ svm_range_add_list_work(struct svm_range_list *svms, struct svm_range *prange,\n \t\t    prange->work_item.op != SVM_OP_UNMAP_RANGE)\n \t\t\tprange->work_item.op = op;\n \t} else {\n-\t\tprange->work_item.op = op;\n-\n-\t\t/* Pairs with mmput in deferred_list_work */\n-\t\tmmget(mm);\n-\t\tprange->work_item.mm = mm;\n-\t\tlist_add_tail(&prange->deferred_list,\n-\t\t\t      &prange->svms->deferred_range_list);\n-\t\tpr_debug(\"add prange 0x%p [0x%lx 0x%lx] to work list op %d\\n\",\n-\t\t\t prange, prange->start, prange->last, op);\n+\t\t/* Pairs with mmput in deferred_list_work.\n+\t\t * If process is exiting and mm is gone, don't update mmu notifier.\n+\t\t */\n+\t\tif (mmget_not_zero(mm)) {\n+\t\t\tprange->work_item.mm = mm;\n+\t\t\tprange->work_item.op = op;\n+\t\t\tlist_add_tail(&prange->deferred_list,\n+\t\t\t\t      &prange->svms->deferred_range_list);\n+\t\t\tpr_debug(\"add prange 0x%p [0x%lx 0x%lx] to work list op %d\\n\",\n+\t\t\t\t prange, prange->start, prange->last, op);\n+\t\t}\n \t}\n \tspin_unlock(&svms->deferred_list_lock);\n }\n@@ -2416,8 +2417,7 @@ void schedule_deferred_list_work(struct svm_range_list *svms)\n }\n \n static void\n-svm_range_unmap_split(struct mm_struct *mm, struct svm_range *parent,\n-\t\t      struct svm_range *prange, unsigned long start,\n+svm_range_unmap_split(struct svm_range *parent, struct svm_range *prange, unsigned long start,\n \t\t      unsigned long last)\n {\n \tstruct svm_range *head;\n@@ -2438,12 +2438,12 @@ svm_range_unmap_split(struct mm_struct *mm, struct svm_range *parent,\n \t\tsvm_range_split(tail, last + 1, tail->last, &head);\n \n \tif (head != prange && tail != prange) {\n-\t\tsvm_range_add_child(parent, mm, head, SVM_OP_UNMAP_RANGE);\n-\t\tsvm_range_add_child(parent, mm, tail, SVM_OP_ADD_RANGE);\n+\t\tsvm_range_add_child(parent, head, SVM_OP_UNMAP_RANGE);\n+\t\tsvm_range_add_child(parent, tail, SVM_OP_ADD_RANGE);\n \t} else if (tail != prange) {\n-\t\tsvm_range_add_child(parent, mm, tail, SVM_OP_UNMAP_RANGE);\n+\t\tsvm_range_add_child(parent, tail, SVM_OP_UNMAP_RANGE);\n \t} else if (head != prange) {\n-\t\tsvm_range_add_child(parent, mm, head, SVM_OP_UNMAP_RANGE);\n+\t\tsvm_range_add_child(parent, head, SVM_OP_UNMAP_RANGE);\n \t} else if (parent != prange) {\n \t\tprange->work_item.op = SVM_OP_UNMAP_RANGE;\n \t}\n@@ -2520,14 +2520,14 @@ svm_range_unmap_from_cpu(struct mm_struct *mm, struct svm_range *prange,\n \t\tl = min(last, pchild->last);\n \t\tif (l >= s)\n \t\t\tsvm_range_unmap_from_gpus(pchild, s, l, trigger);\n-\t\tsvm_range_unmap_split(mm, prange, pchild, start, last);\n+\t\tsvm_range_unmap_split(prange, pchild, start, last);\n \t\tmutex_unlock(&pchild->lock);\n \t}\n \ts = max(start, prange->start);\n \tl = min(last, prange->last);\n \tif (l >= s)\n \t\tsvm_range_unmap_from_gpus(prange, s, l, trigger);\n-\tsvm_range_unmap_split(mm, prange, prange, start, last);\n+\tsvm_range_unmap_split(prange, prange, start, last);\n \n \tif (unmap_parent)\n \t\tsvm_range_add_list_work(svms, prange, mm, SVM_OP_UNMAP_RANGE);\n@@ -2570,8 +2570,6 @@ svm_range_cpu_invalidate_pagetables(struct mmu_interval_notifier *mni,\n \n \tif (range->event == MMU_NOTIFY_RELEASE)\n \t\treturn true;\n-\tif (!mmget_not_zero(mni->mm))\n-\t\treturn true;\n \n \tstart = mni->interval_tree.start;\n \tlast = mni->interval_tree.last;\n@@ -2598,7 +2596,6 @@ svm_range_cpu_invalidate_pagetables(struct mmu_interval_notifier *mni,\n \t}\n \n \tsvm_range_unlock(prange);\n-\tmmput(mni->mm);\n \n \treturn true;\n }",
    "stats": {
      "insertions": 20,
      "deletions": 23,
      "files": 1
    }
  },
  {
    "sha": "3d30048958e0d43425f6d4e76565e6249fa71050",
    "message": "i2c/designware: Fix an initialization issue\n\nThe i2c_dw_xfer_init() function requires msgs and msg_write_idx from the\ndev context to be initialized.\n\namd_i2c_dw_xfer_quirk() inits msgs and msgs_num, but not msg_write_idx.\n\nThis could allow an out of bounds access (of msgs).\n\nInitialize msg_write_idx before calling i2c_dw_xfer_init().\n\nReviewed-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>\nFixes: 17631e8ca2d3 (\"i2c: designware: Add driver support for AMD NAVI GPU\")\nCc: <stable@vger.kernel.org> # v5.13+\nSigned-off-by: Michael J. Ruhl <michael.j.ruhl@intel.com>\nSigned-off-by: Andi Shyti <andi.shyti@kernel.org>\nLink: https://lore.kernel.org/r/20250627143511.489570-1-michael.j.ruhl@intel.com",
    "author": "Michael J. Ruhl",
    "date": "2025-06-30T19:57:08+02:00",
    "files_changed": [
      "drivers/i2c/busses/i2c-designware-master.c"
    ],
    "diff": "diff --git a/drivers/i2c/busses/i2c-designware-master.c b/drivers/i2c/busses/i2c-designware-master.c\nindex 9d7d9e47564a..cbd88ffa5610 100644\n--- a/drivers/i2c/busses/i2c-designware-master.c\n+++ b/drivers/i2c/busses/i2c-designware-master.c\n@@ -363,6 +363,7 @@ static int amd_i2c_dw_xfer_quirk(struct i2c_adapter *adap, struct i2c_msg *msgs,\n \n \tdev->msgs = msgs;\n \tdev->msgs_num = num_msgs;\n+\tdev->msg_write_idx = 0;\n \ti2c_dw_xfer_init(dev);\n \n \t/* Initiate messages read/write transaction */",
    "stats": {
      "insertions": 1,
      "deletions": 0,
      "files": 1
    }
  }
]