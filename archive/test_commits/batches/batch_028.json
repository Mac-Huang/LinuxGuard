[
  {
    "sha": "fa33adcaf8af147f4238c84d76a316a47e43e091",
    "message": "Merge tag 'pci-v6.16-fixes-2' of git://git.kernel.org/pub/scm/linux/kernel/git/pci/pci\n\nPull PCI fix from Bjorn Helgaas:\n\n - Fix a PTM debugfs build error with CONFIG_DEBUG_FS=n &&\n   CONFIG_PCIE_PTM=y (Manivannan Sadhasivam)\n\n* tag 'pci-v6.16-fixes-2' of git://git.kernel.org/pub/scm/linux/kernel/git/pci/pci:\n  PCI/PTM: Build debugfs code only if CONFIG_DEBUG_FS is enabled",
    "author": "Linus Torvalds",
    "date": "2025-06-27T20:17:48-07:00",
    "files_changed": [
      "drivers/pci/pcie/ptm.c"
    ],
    "diff": "diff --git a/drivers/pci/pcie/ptm.c b/drivers/pci/pcie/ptm.c\nindex ee5f615a9023..4bd73f038ffb 100644\n--- a/drivers/pci/pcie/ptm.c\n+++ b/drivers/pci/pcie/ptm.c\n@@ -254,6 +254,7 @@ bool pcie_ptm_enabled(struct pci_dev *dev)\n }\n EXPORT_SYMBOL(pcie_ptm_enabled);\n \n+#if IS_ENABLED(CONFIG_DEBUG_FS)\n static ssize_t context_update_write(struct file *file, const char __user *ubuf,\n \t\t\t     size_t count, loff_t *ppos)\n {\n@@ -552,3 +553,4 @@ void pcie_ptm_destroy_debugfs(struct pci_ptm_debugfs *ptm_debugfs)\n \tdebugfs_remove_recursive(ptm_debugfs->debugfs);\n }\n EXPORT_SYMBOL_GPL(pcie_ptm_destroy_debugfs);\n+#endif",
    "stats": {
      "insertions": 2,
      "deletions": 0,
      "files": 1
    }
  },
  {
    "sha": "7abdafd2343ab199367c8243d6a5f06a9aa6976b",
    "message": "Merge tag 'drm-fixes-2025-06-28' of https://gitlab.freedesktop.org/drm/kernel\n\nPull drm fixes from Dave Airlie:\n \"Regular weekly drm updates, nothing out of the ordinary, amdgpu, xe,\n  i915 and a few misc bits. Seems about right for this time in the\n  release cycle.\n\n  core:\n   - fix drm_writeback_connector_cleanup function signature\n   - use correct HDMI audio bridge in drm_connector_hdmi_audio_init\n\n  bridge:\n   - SN65DSI86: fix HPD\n\n  amdgpu:\n   - Cleaner shader support for additional GFX9 GPUs\n   - MES firmware compatibility fixes\n   - Discovery error reporting fixes\n   - SDMA6/7 userq fixes\n   - Backlight fix\n   - EDID sanity check\n\n  i915:\n   - Fix for SNPS PHY HDMI for 1080p@120Hz\n   - Correct DP AUX DPCD probe address\n   - Followup build fix for GCOV and AutoFDO enabled config\n\n  xe:\n   - Missing error check\n   - Fix xe_hwmon_power_max_write\n   - Move flushes\n   - Explicitly exit CT safe mode on unwind\n   - Process deferred GGTT node removals on device unwind\"\n\n* tag 'drm-fixes-2025-06-28' of https://gitlab.freedesktop.org/drm/kernel:\n  drm/xe: Process deferred GGTT node removals on device unwind\n  drm/xe/guc: Explicitly exit CT safe mode on unwind\n  drm/xe: move DPT l2 flush to a more sensible place\n  drm/xe: Move DSB l2 flush to a more sensible place\n  drm/bridge: ti-sn65dsi86: Add HPD for DisplayPort connector type\n  drm/i915: fix build error some more\n  drm/xe/hwmon: Fix xe_hwmon_power_max_write\n  drm/xe/display: Add check for alloc_ordered_workqueue()\n  drm/amd/display: Add sanity checks for drm_edid_raw()\n  drm/amd/display: Fix AMDGPU_MAX_BL_LEVEL value\n  drm/amdgpu/sdma7: add ucode version checks for userq support\n  drm/amdgpu/sdma6: add ucode version checks for userq support\n  drm/amd: Adjust output for discovery error handling\n  drm/amdgpu/mes: add compatibility checks for set_hw_resource_1\n  drm/amdgpu/gfx9: Add Cleaner Shader Support for GFX9.x GPUs\n  drm/bridge-connector: Fix bridge in drm_connector_hdmi_audio_init()\n  drm/dp: Change AUX DPCD probe address from DPCD_REV to LANE0_1_STATUS\n  drm/i915/snps_hdmi_pll: Fix 64-bit divisor truncation by using div64_u64\n  drm: writeback: Fix drm_writeback_connector_cleanup signature",
    "author": "Linus Torvalds",
    "date": "2025-06-27T19:38:36-07:00",
    "files_changed": [
      "drivers/gpu/drm/amd/amdgpu/amdgpu_discovery.c",
      "drivers/gpu/drm/amd/amdgpu/gfx_v9_0.c",
      "drivers/gpu/drm/amd/amdgpu/mes_v11_0.c",
      "drivers/gpu/drm/amd/amdgpu/mes_v12_0.c",
      "drivers/gpu/drm/amd/amdgpu/sdma_v6_0.c",
      "drivers/gpu/drm/amd/amdgpu/sdma_v7_0.c",
      "drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c",
      "drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm_helpers.c",
      "drivers/gpu/drm/bridge/ti-sn65dsi86.c",
      "drivers/gpu/drm/display/drm_bridge_connector.c",
      "drivers/gpu/drm/display/drm_dp_helper.c",
      "drivers/gpu/drm/drm_writeback.c",
      "drivers/gpu/drm/i915/display/intel_snps_hdmi_pll.c",
      "drivers/gpu/drm/i915/i915_pmu.c",
      "drivers/gpu/drm/xe/display/xe_display.c",
      "drivers/gpu/drm/xe/display/xe_dsb_buffer.c",
      "drivers/gpu/drm/xe/display/xe_fb_pin.c",
      "drivers/gpu/drm/xe/regs/xe_mchbar_regs.h",
      "drivers/gpu/drm/xe/xe_ggtt.c",
      "drivers/gpu/drm/xe/xe_guc_ct.c",
      "drivers/gpu/drm/xe/xe_hwmon.c"
    ],
    "diff": "diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_discovery.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_discovery.c\nindex a0e9bf9b2710..81b3443c8d7f 100644\n--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_discovery.c\n+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_discovery.c\n@@ -321,10 +321,12 @@ static int amdgpu_discovery_read_binary_from_file(struct amdgpu_device *adev,\n \tconst struct firmware *fw;\n \tint r;\n \n-\tr = request_firmware(&fw, fw_name, adev->dev);\n+\tr = firmware_request_nowarn(&fw, fw_name, adev->dev);\n \tif (r) {\n-\t\tdev_err(adev->dev, \"can't load firmware \\\"%s\\\"\\n\",\n-\t\t\tfw_name);\n+\t\tif (amdgpu_discovery == 2)\n+\t\t\tdev_err(adev->dev, \"can't load firmware \\\"%s\\\"\\n\", fw_name);\n+\t\telse\n+\t\t\tdrm_info(&adev->ddev, \"Optional firmware \\\"%s\\\" was not found\\n\", fw_name);\n \t\treturn r;\n \t}\n \n@@ -459,16 +461,12 @@ static int amdgpu_discovery_init(struct amdgpu_device *adev)\n \t/* Read from file if it is the preferred option */\n \tfw_name = amdgpu_discovery_get_fw_name(adev);\n \tif (fw_name != NULL) {\n-\t\tdev_info(adev->dev, \"use ip discovery information from file\");\n+\t\tdrm_dbg(&adev->ddev, \"use ip discovery information from file\");\n \t\tr = amdgpu_discovery_read_binary_from_file(adev, adev->mman.discovery_bin, fw_name);\n-\n-\t\tif (r) {\n-\t\t\tdev_err(adev->dev, \"failed to read ip discovery binary from file\\n\");\n-\t\t\tr = -EINVAL;\n+\t\tif (r)\n \t\t\tgoto out;\n-\t\t}\n-\n \t} else {\n+\t\tdrm_dbg(&adev->ddev, \"use ip discovery information from memory\");\n \t\tr = amdgpu_discovery_read_binary_from_mem(\n \t\t\tadev, adev->mman.discovery_bin);\n \t\tif (r)\n@@ -1338,10 +1336,8 @@ static int amdgpu_discovery_reg_base_init(struct amdgpu_device *adev)\n \tint r;\n \n \tr = amdgpu_discovery_init(adev);\n-\tif (r) {\n-\t\tDRM_ERROR(\"amdgpu_discovery_init failed\\n\");\n+\tif (r)\n \t\treturn r;\n-\t}\n \n \twafl_ver = 0;\n \tadev->gfx.xcc_mask = 0;\n@@ -2579,8 +2575,10 @@ int amdgpu_discovery_set_ip_blocks(struct amdgpu_device *adev)\n \t\tbreak;\n \tdefault:\n \t\tr = amdgpu_discovery_reg_base_init(adev);\n-\t\tif (r)\n-\t\t\treturn -EINVAL;\n+\t\tif (r) {\n+\t\t\tdrm_err(&adev->ddev, \"discovery failed: %d\\n\", r);\n+\t\t\treturn r;\n+\t\t}\n \n \t\tamdgpu_discovery_harvest_ip(adev);\n \t\tamdgpu_discovery_get_gfx_info(adev);\ndiff --git a/drivers/gpu/drm/amd/amdgpu/gfx_v9_0.c b/drivers/gpu/drm/amd/amdgpu/gfx_v9_0.c\nindex d377a7c57d5e..ad9be3656653 100644\n--- a/drivers/gpu/drm/amd/amdgpu/gfx_v9_0.c\n+++ b/drivers/gpu/drm/amd/amdgpu/gfx_v9_0.c\n@@ -2235,6 +2235,25 @@ static int gfx_v9_0_sw_init(struct amdgpu_ip_block *ip_block)\n \t}\n \n \tswitch (amdgpu_ip_version(adev, GC_HWIP, 0)) {\n+\tcase IP_VERSION(9, 0, 1):\n+\tcase IP_VERSION(9, 2, 1):\n+\tcase IP_VERSION(9, 4, 0):\n+\tcase IP_VERSION(9, 2, 2):\n+\tcase IP_VERSION(9, 1, 0):\n+\tcase IP_VERSION(9, 3, 0):\n+\t\tadev->gfx.cleaner_shader_ptr = gfx_9_4_2_cleaner_shader_hex;\n+\t\tadev->gfx.cleaner_shader_size = sizeof(gfx_9_4_2_cleaner_shader_hex);\n+\t\tif (adev->gfx.me_fw_version  >= 167 &&\n+\t\t    adev->gfx.pfp_fw_version >= 196 &&\n+\t\t    adev->gfx.mec_fw_version >= 474) {\n+\t\t\tadev->gfx.enable_cleaner_shader = true;\n+\t\t\tr = amdgpu_gfx_cleaner_shader_sw_init(adev, adev->gfx.cleaner_shader_size);\n+\t\t\tif (r) {\n+\t\t\t\tadev->gfx.enable_cleaner_shader = false;\n+\t\t\t\tdev_err(adev->dev, \"Failed to initialize cleaner shader\\n\");\n+\t\t\t}\n+\t\t}\n+\t\tbreak;\n \tcase IP_VERSION(9, 4, 2):\n \t\tadev->gfx.cleaner_shader_ptr = gfx_9_4_2_cleaner_shader_hex;\n \t\tadev->gfx.cleaner_shader_size = sizeof(gfx_9_4_2_cleaner_shader_hex);\ndiff --git a/drivers/gpu/drm/amd/amdgpu/mes_v11_0.c b/drivers/gpu/drm/amd/amdgpu/mes_v11_0.c\nindex c9eba537de09..28eb846280dd 100644\n--- a/drivers/gpu/drm/amd/amdgpu/mes_v11_0.c\n+++ b/drivers/gpu/drm/amd/amdgpu/mes_v11_0.c\n@@ -1630,10 +1630,12 @@ static int mes_v11_0_hw_init(struct amdgpu_ip_block *ip_block)\n \tif (r)\n \t\tgoto failure;\n \n-\tr = mes_v11_0_set_hw_resources_1(&adev->mes);\n-\tif (r) {\n-\t\tDRM_ERROR(\"failed mes_v11_0_set_hw_resources_1, r=%d\\n\", r);\n-\t\tgoto failure;\n+\tif ((adev->mes.sched_version & AMDGPU_MES_VERSION_MASK) >= 0x50) {\n+\t\tr = mes_v11_0_set_hw_resources_1(&adev->mes);\n+\t\tif (r) {\n+\t\t\tDRM_ERROR(\"failed mes_v11_0_set_hw_resources_1, r=%d\\n\", r);\n+\t\t\tgoto failure;\n+\t\t}\n \t}\n \n \tr = mes_v11_0_query_sched_status(&adev->mes);\ndiff --git a/drivers/gpu/drm/amd/amdgpu/mes_v12_0.c b/drivers/gpu/drm/amd/amdgpu/mes_v12_0.c\nindex b4f17332d466..6b222630f3fa 100644\n--- a/drivers/gpu/drm/amd/amdgpu/mes_v12_0.c\n+++ b/drivers/gpu/drm/amd/amdgpu/mes_v12_0.c\n@@ -1742,7 +1742,8 @@ static int mes_v12_0_hw_init(struct amdgpu_ip_block *ip_block)\n \tif (r)\n \t\tgoto failure;\n \n-\tmes_v12_0_set_hw_resources_1(&adev->mes, AMDGPU_MES_SCHED_PIPE);\n+\tif ((adev->mes.sched_version & AMDGPU_MES_VERSION_MASK) >= 0x4b)\n+\t\tmes_v12_0_set_hw_resources_1(&adev->mes, AMDGPU_MES_SCHED_PIPE);\n \n \tmes_v12_0_init_aggregated_doorbell(&adev->mes);\n \ndiff --git a/drivers/gpu/drm/amd/amdgpu/sdma_v6_0.c b/drivers/gpu/drm/amd/amdgpu/sdma_v6_0.c\nindex 5a70ae17be04..a9bdf8d61d6c 100644\n--- a/drivers/gpu/drm/amd/amdgpu/sdma_v6_0.c\n+++ b/drivers/gpu/drm/amd/amdgpu/sdma_v6_0.c\n@@ -1374,9 +1374,22 @@ static int sdma_v6_0_sw_init(struct amdgpu_ip_block *ip_block)\n \telse\n \t\tDRM_ERROR(\"Failed to allocated memory for SDMA IP Dump\\n\");\n \n-\t/* add firmware version checks here */\n-\tif (0 && !adev->sdma.disable_uq)\n-\t\tadev->userq_funcs[AMDGPU_HW_IP_DMA] = &userq_mes_funcs;\n+\tswitch (amdgpu_ip_version(adev, SDMA0_HWIP, 0)) {\n+\tcase IP_VERSION(6, 0, 0):\n+\t\tif ((adev->sdma.instance[0].fw_version >= 24) && !adev->sdma.disable_uq)\n+\t\t\tadev->userq_funcs[AMDGPU_HW_IP_DMA] = &userq_mes_funcs;\n+\t\tbreak;\n+\tcase IP_VERSION(6, 0, 2):\n+\t\tif ((adev->sdma.instance[0].fw_version >= 21) && !adev->sdma.disable_uq)\n+\t\t\tadev->userq_funcs[AMDGPU_HW_IP_DMA] = &userq_mes_funcs;\n+\t\tbreak;\n+\tcase IP_VERSION(6, 0, 3):\n+\t\tif ((adev->sdma.instance[0].fw_version >= 25) && !adev->sdma.disable_uq)\n+\t\t\tadev->userq_funcs[AMDGPU_HW_IP_DMA] = &userq_mes_funcs;\n+\t\tbreak;\n+\tdefault:\n+\t\tbreak;\n+\t}\n \n \tr = amdgpu_sdma_sysfs_reset_mask_init(adev);\n \tif (r)\ndiff --git a/drivers/gpu/drm/amd/amdgpu/sdma_v7_0.c b/drivers/gpu/drm/amd/amdgpu/sdma_v7_0.c\nindex ad47d0bdf777..86903eccbd4e 100644\n--- a/drivers/gpu/drm/amd/amdgpu/sdma_v7_0.c\n+++ b/drivers/gpu/drm/amd/amdgpu/sdma_v7_0.c\n@@ -1349,9 +1349,15 @@ static int sdma_v7_0_sw_init(struct amdgpu_ip_block *ip_block)\n \telse\n \t\tDRM_ERROR(\"Failed to allocated memory for SDMA IP Dump\\n\");\n \n-\t/* add firmware version checks here */\n-\tif (0 && !adev->sdma.disable_uq)\n-\t\tadev->userq_funcs[AMDGPU_HW_IP_DMA] = &userq_mes_funcs;\n+\tswitch (amdgpu_ip_version(adev, SDMA0_HWIP, 0)) {\n+\tcase IP_VERSION(7, 0, 0):\n+\tcase IP_VERSION(7, 0, 1):\n+\t\tif ((adev->sdma.instance[0].fw_version >= 7836028) && !adev->sdma.disable_uq)\n+\t\t\tadev->userq_funcs[AMDGPU_HW_IP_DMA] = &userq_mes_funcs;\n+\t\tbreak;\n+\tdefault:\n+\t\tbreak;\n+\t}\n \n \treturn r;\n }\ndiff --git a/drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c b/drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c\nindex bc4cd11bfc79..0b8ac9edc070 100644\n--- a/drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c\n+++ b/drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c\n@@ -4718,16 +4718,16 @@ static int get_brightness_range(const struct amdgpu_dm_backlight_caps *caps,\n \treturn 1;\n }\n \n-/* Rescale from [min..max] to [0..AMDGPU_MAX_BL_LEVEL] */\n+/* Rescale from [min..max] to [0..MAX_BACKLIGHT_LEVEL] */\n static inline u32 scale_input_to_fw(int min, int max, u64 input)\n {\n-\treturn DIV_ROUND_CLOSEST_ULL(input * AMDGPU_MAX_BL_LEVEL, max - min);\n+\treturn DIV_ROUND_CLOSEST_ULL(input * MAX_BACKLIGHT_LEVEL, max - min);\n }\n \n-/* Rescale from [0..AMDGPU_MAX_BL_LEVEL] to [min..max] */\n+/* Rescale from [0..MAX_BACKLIGHT_LEVEL] to [min..max] */\n static inline u32 scale_fw_to_input(int min, int max, u64 input)\n {\n-\treturn min + DIV_ROUND_CLOSEST_ULL(input * (max - min), AMDGPU_MAX_BL_LEVEL);\n+\treturn min + DIV_ROUND_CLOSEST_ULL(input * (max - min), MAX_BACKLIGHT_LEVEL);\n }\n \n static void convert_custom_brightness(const struct amdgpu_dm_backlight_caps *caps,\n@@ -4947,7 +4947,7 @@ amdgpu_dm_register_backlight_device(struct amdgpu_dm_connector *aconnector)\n \t\tdrm_dbg(drm, \"Backlight caps: min: %d, max: %d, ac %d, dc %d\\n\", min, max,\n \t\t\tcaps->ac_level, caps->dc_level);\n \t} else\n-\t\tprops.brightness = props.max_brightness = AMDGPU_MAX_BL_LEVEL;\n+\t\tprops.brightness = props.max_brightness = MAX_BACKLIGHT_LEVEL;\n \n \tif (caps->data_points && !(amdgpu_dc_debug_mask & DC_DISABLE_CUSTOM_BRIGHTNESS_CURVE))\n \t\tdrm_info(drm, \"Using custom brightness curve\\n\");\ndiff --git a/drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm_helpers.c b/drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm_helpers.c\nindex d4395b92fb85..9e3e51a2dc49 100644\n--- a/drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm_helpers.c\n+++ b/drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm_helpers.c\n@@ -1029,6 +1029,10 @@ enum dc_edid_status dm_helpers_read_local_edid(\n \t\t\treturn EDID_NO_RESPONSE;\n \n \t\tedid = drm_edid_raw(drm_edid); // FIXME: Get rid of drm_edid_raw()\n+\t\tif (!edid ||\n+\t\t    edid->extensions >= sizeof(sink->dc_edid.raw_edid) / EDID_LENGTH)\n+\t\t\treturn EDID_BAD_INPUT;\n+\n \t\tsink->dc_edid.length = EDID_LENGTH * (edid->extensions + 1);\n \t\tmemmove(sink->dc_edid.raw_edid, (uint8_t *)edid, sink->dc_edid.length);\n \ndiff --git a/drivers/gpu/drm/bridge/ti-sn65dsi86.c b/drivers/gpu/drm/bridge/ti-sn65dsi86.c\nindex 60224f476e1d..de9c23537465 100644\n--- a/drivers/gpu/drm/bridge/ti-sn65dsi86.c\n+++ b/drivers/gpu/drm/bridge/ti-sn65dsi86.c\n@@ -348,12 +348,18 @@ static void ti_sn65dsi86_enable_comms(struct ti_sn65dsi86 *pdata,\n \t * 200 ms.  We'll assume that the panel driver will have the hardcoded\n \t * delay in its prepare and always disable HPD.\n \t *\n-\t * If HPD somehow makes sense on some future panel we'll have to\n-\t * change this to be conditional on someone specifying that HPD should\n-\t * be used.\n+\t * For DisplayPort bridge type, we need HPD. So we use the bridge type\n+\t * to conditionally disable HPD.\n+\t * NOTE: The bridge type is set in ti_sn_bridge_probe() but enable_comms()\n+\t * can be called before. So for DisplayPort, HPD will be enabled once\n+\t * bridge type is set. We are using bridge type instead of \"no-hpd\"\n+\t * property because it is not used properly in devicetree description\n+\t * and hence is unreliable.\n \t */\n-\tregmap_update_bits(pdata->regmap, SN_HPD_DISABLE_REG, HPD_DISABLE,\n-\t\t\t   HPD_DISABLE);\n+\n+\tif (pdata->bridge.type != DRM_MODE_CONNECTOR_DisplayPort)\n+\t\tregmap_update_bits(pdata->regmap, SN_HPD_DISABLE_REG, HPD_DISABLE,\n+\t\t\t\t   HPD_DISABLE);\n \n \tpdata->comms_enabled = true;\n \n@@ -1195,9 +1201,14 @@ static enum drm_connector_status ti_sn_bridge_detect(struct drm_bridge *bridge)\n \tstruct ti_sn65dsi86 *pdata = bridge_to_ti_sn65dsi86(bridge);\n \tint val = 0;\n \n-\tpm_runtime_get_sync(pdata->dev);\n+\t/*\n+\t * Runtime reference is grabbed in ti_sn_bridge_hpd_enable()\n+\t * as the chip won't report HPD just after being powered on.\n+\t * HPD_DEBOUNCED_STATE reflects correct state only after the\n+\t * debounce time (~100-400 ms).\n+\t */\n+\n \tregmap_read(pdata->regmap, SN_HPD_DISABLE_REG, &val);\n-\tpm_runtime_put_autosuspend(pdata->dev);\n \n \treturn val & HPD_DEBOUNCED_STATE ? connector_status_connected\n \t\t\t\t\t : connector_status_disconnected;\n@@ -1220,6 +1231,26 @@ static void ti_sn65dsi86_debugfs_init(struct drm_bridge *bridge, struct dentry *\n \tdebugfs_create_file(\"status\", 0600, debugfs, pdata, &status_fops);\n }\n \n+static void ti_sn_bridge_hpd_enable(struct drm_bridge *bridge)\n+{\n+\tstruct ti_sn65dsi86 *pdata = bridge_to_ti_sn65dsi86(bridge);\n+\n+\t/*\n+\t * Device needs to be powered on before reading the HPD state\n+\t * for reliable hpd detection in ti_sn_bridge_detect() due to\n+\t * the high debounce time.\n+\t */\n+\n+\tpm_runtime_get_sync(pdata->dev);\n+}\n+\n+static void ti_sn_bridge_hpd_disable(struct drm_bridge *bridge)\n+{\n+\tstruct ti_sn65dsi86 *pdata = bridge_to_ti_sn65dsi86(bridge);\n+\n+\tpm_runtime_put_autosuspend(pdata->dev);\n+}\n+\n static const struct drm_bridge_funcs ti_sn_bridge_funcs = {\n \t.attach = ti_sn_bridge_attach,\n \t.detach = ti_sn_bridge_detach,\n@@ -1234,6 +1265,8 @@ static const struct drm_bridge_funcs ti_sn_bridge_funcs = {\n \t.atomic_duplicate_state = drm_atomic_helper_bridge_duplicate_state,\n \t.atomic_destroy_state = drm_atomic_helper_bridge_destroy_state,\n \t.debugfs_init = ti_sn65dsi86_debugfs_init,\n+\t.hpd_enable = ti_sn_bridge_hpd_enable,\n+\t.hpd_disable = ti_sn_bridge_hpd_disable,\n };\n \n static void ti_sn_bridge_parse_lanes(struct ti_sn65dsi86 *pdata,\n@@ -1321,8 +1354,26 @@ static int ti_sn_bridge_probe(struct auxiliary_device *adev,\n \tpdata->bridge.type = pdata->next_bridge->type == DRM_MODE_CONNECTOR_DisplayPort\n \t\t\t   ? DRM_MODE_CONNECTOR_DisplayPort : DRM_MODE_CONNECTOR_eDP;\n \n-\tif (pdata->bridge.type == DRM_MODE_CONNECTOR_DisplayPort)\n-\t\tpdata->bridge.ops = DRM_BRIDGE_OP_EDID | DRM_BRIDGE_OP_DETECT;\n+\tif (pdata->bridge.type == DRM_MODE_CONNECTOR_DisplayPort) {\n+\t\tpdata->bridge.ops = DRM_BRIDGE_OP_EDID | DRM_BRIDGE_OP_DETECT |\n+\t\t\t\t    DRM_BRIDGE_OP_HPD;\n+\t\t/*\n+\t\t * If comms were already enabled they would have been enabled\n+\t\t * with the wrong value of HPD_DISABLE. Update it now. Comms\n+\t\t * could be enabled if anyone is holding a pm_runtime reference\n+\t\t * (like if a GPIO is in use). Note that in most cases nobody\n+\t\t * is doing AUX channel xfers before the bridge is added so\n+\t\t * HPD doesn't _really_ matter then. The only exception is in\n+\t\t * the eDP case where the panel wants to read the EDID before\n+\t\t * the bridge is added. We always consistently have HPD disabled\n+\t\t * for eDP.\n+\t\t */\n+\t\tmutex_lock(&pdata->comms_mutex);\n+\t\tif (pdata->comms_enabled)\n+\t\t\tregmap_update_bits(pdata->regmap, SN_HPD_DISABLE_REG,\n+\t\t\t\t\t   HPD_DISABLE, 0);\n+\t\tmutex_unlock(&pdata->comms_mutex);\n+\t};\n \n \tdrm_bridge_add(&pdata->bridge);\n \ndiff --git a/drivers/gpu/drm/display/drm_bridge_connector.c b/drivers/gpu/drm/display/drm_bridge_connector.c\nindex 7d2e499ea5de..262e93e07a28 100644\n--- a/drivers/gpu/drm/display/drm_bridge_connector.c\n+++ b/drivers/gpu/drm/display/drm_bridge_connector.c\n@@ -708,11 +708,14 @@ struct drm_connector *drm_bridge_connector_init(struct drm_device *drm,\n \tif (bridge_connector->bridge_hdmi_audio ||\n \t    bridge_connector->bridge_dp_audio) {\n \t\tstruct device *dev;\n+\t\tstruct drm_bridge *bridge;\n \n \t\tif (bridge_connector->bridge_hdmi_audio)\n-\t\t\tdev = bridge_connector->bridge_hdmi_audio->hdmi_audio_dev;\n+\t\t\tbridge = bridge_connector->bridge_hdmi_audio;\n \t\telse\n-\t\t\tdev = bridge_connector->bridge_dp_audio->hdmi_audio_dev;\n+\t\t\tbridge = bridge_connector->bridge_dp_audio;\n+\n+\t\tdev = bridge->hdmi_audio_dev;\n \n \t\tret = drm_connector_hdmi_audio_init(connector, dev,\n \t\t\t\t\t\t    &drm_bridge_connector_hdmi_audio_funcs,\ndiff --git a/drivers/gpu/drm/display/drm_dp_helper.c b/drivers/gpu/drm/display/drm_dp_helper.c\nindex f2a6559a2710..dc622c78db9d 100644\n--- a/drivers/gpu/drm/display/drm_dp_helper.c\n+++ b/drivers/gpu/drm/display/drm_dp_helper.c\n@@ -725,7 +725,7 @@ ssize_t drm_dp_dpcd_read(struct drm_dp_aux *aux, unsigned int offset,\n \t * monitor doesn't power down exactly after the throw away read.\n \t */\n \tif (!aux->is_remote) {\n-\t\tret = drm_dp_dpcd_probe(aux, DP_DPCD_REV);\n+\t\tret = drm_dp_dpcd_probe(aux, DP_LANE0_1_STATUS);\n \t\tif (ret < 0)\n \t\t\treturn ret;\n \t}\ndiff --git a/drivers/gpu/drm/drm_writeback.c b/drivers/gpu/drm/drm_writeback.c\nindex edbeab88ff2b..d983ee85cf13 100644\n--- a/drivers/gpu/drm/drm_writeback.c\n+++ b/drivers/gpu/drm/drm_writeback.c\n@@ -343,17 +343,18 @@ EXPORT_SYMBOL(drm_writeback_connector_init_with_encoder);\n /**\n  * drm_writeback_connector_cleanup - Cleanup the writeback connector\n  * @dev: DRM device\n- * @wb_connector: Pointer to the writeback connector to clean up\n+ * @data: Pointer to the writeback connector to clean up\n  *\n  * This will decrement the reference counter of blobs and destroy properties. It\n  * will also clean the remaining jobs in this writeback connector. Caution: This helper will not\n  * clean up the attached encoder and the drm_connector.\n  */\n static void drm_writeback_connector_cleanup(struct drm_device *dev,\n-\t\t\t\t\t    struct drm_writeback_connector *wb_connector)\n+\t\t\t\t\t    void *data)\n {\n \tunsigned long flags;\n \tstruct drm_writeback_job *pos, *n;\n+\tstruct drm_writeback_connector *wb_connector = data;\n \n \tdelete_writeback_properties(dev);\n \tdrm_property_blob_put(wb_connector->pixel_formats_blob_ptr);\n@@ -405,7 +406,7 @@ int drmm_writeback_connector_init(struct drm_device *dev,\n \tif (ret)\n \t\treturn ret;\n \n-\tret = drmm_add_action_or_reset(dev, (void *)drm_writeback_connector_cleanup,\n+\tret = drmm_add_action_or_reset(dev, drm_writeback_connector_cleanup,\n \t\t\t\t       wb_connector);\n \tif (ret)\n \t\treturn ret;\ndiff --git a/drivers/gpu/drm/i915/display/intel_snps_hdmi_pll.c b/drivers/gpu/drm/i915/display/intel_snps_hdmi_pll.c\nindex 74bb3bedf30f..5111bdc3075b 100644\n--- a/drivers/gpu/drm/i915/display/intel_snps_hdmi_pll.c\n+++ b/drivers/gpu/drm/i915/display/intel_snps_hdmi_pll.c\n@@ -103,8 +103,8 @@ static void get_ana_cp_int_prop(u64 vco_clk,\n \t\t\t    DIV_ROUND_DOWN_ULL(curve_1_interpolated, CURVE0_MULTIPLIER)));\n \n \tana_cp_int_temp =\n-\t\tDIV_ROUND_CLOSEST_ULL(DIV_ROUND_DOWN_ULL(adjusted_vco_clk1, curve_2_scaled1),\n-\t\t\t\t      CURVE2_MULTIPLIER);\n+\t\tDIV64_U64_ROUND_CLOSEST(DIV_ROUND_DOWN_ULL(adjusted_vco_clk1, curve_2_scaled1),\n+\t\t\t\t\tCURVE2_MULTIPLIER);\n \n \t*ana_cp_int = max(1, min(ana_cp_int_temp, 127));\n \ndiff --git a/drivers/gpu/drm/i915/i915_pmu.c b/drivers/gpu/drm/i915/i915_pmu.c\nindex 990bfaba3ce4..5bc696bfbb0f 100644\n--- a/drivers/gpu/drm/i915/i915_pmu.c\n+++ b/drivers/gpu/drm/i915/i915_pmu.c\n@@ -108,7 +108,7 @@ static unsigned int config_bit(const u64 config)\n \t\treturn other_bit(config);\n }\n \n-static u32 config_mask(const u64 config)\n+static __always_inline u32 config_mask(const u64 config)\n {\n \tunsigned int bit = config_bit(config);\n \ndiff --git a/drivers/gpu/drm/xe/display/xe_display.c b/drivers/gpu/drm/xe/display/xe_display.c\nindex 68f064f33d4b..9f4ade25787a 100644\n--- a/drivers/gpu/drm/xe/display/xe_display.c\n+++ b/drivers/gpu/drm/xe/display/xe_display.c\n@@ -104,6 +104,8 @@ int xe_display_create(struct xe_device *xe)\n \tspin_lock_init(&xe->display.fb_tracking.lock);\n \n \txe->display.hotplug.dp_wq = alloc_ordered_workqueue(\"xe-dp\", 0);\n+\tif (!xe->display.hotplug.dp_wq)\n+\t\treturn -ENOMEM;\n \n \treturn drmm_add_action_or_reset(&xe->drm, display_destroy, NULL);\n }\ndiff --git a/drivers/gpu/drm/xe/display/xe_dsb_buffer.c b/drivers/gpu/drm/xe/display/xe_dsb_buffer.c\nindex f95375451e2f..9f941fc2e36b 100644\n--- a/drivers/gpu/drm/xe/display/xe_dsb_buffer.c\n+++ b/drivers/gpu/drm/xe/display/xe_dsb_buffer.c\n@@ -17,10 +17,7 @@ u32 intel_dsb_buffer_ggtt_offset(struct intel_dsb_buffer *dsb_buf)\n \n void intel_dsb_buffer_write(struct intel_dsb_buffer *dsb_buf, u32 idx, u32 val)\n {\n-\tstruct xe_device *xe = dsb_buf->vma->bo->tile->xe;\n-\n \tiosys_map_wr(&dsb_buf->vma->bo->vmap, idx * 4, u32, val);\n-\txe_device_l2_flush(xe);\n }\n \n u32 intel_dsb_buffer_read(struct intel_dsb_buffer *dsb_buf, u32 idx)\n@@ -30,12 +27,9 @@ u32 intel_dsb_buffer_read(struct intel_dsb_buffer *dsb_buf, u32 idx)\n \n void intel_dsb_buffer_memset(struct intel_dsb_buffer *dsb_buf, u32 idx, u32 val, size_t size)\n {\n-\tstruct xe_device *xe = dsb_buf->vma->bo->tile->xe;\n-\n \tWARN_ON(idx > (dsb_buf->buf_size - size) / sizeof(*dsb_buf->cmd_buf));\n \n \tiosys_map_memset(&dsb_buf->vma->bo->vmap, idx * 4, val, size);\n-\txe_device_l2_flush(xe);\n }\n \n bool intel_dsb_buffer_create(struct intel_crtc *crtc, struct intel_dsb_buffer *dsb_buf, size_t size)\n@@ -74,9 +68,12 @@ void intel_dsb_buffer_cleanup(struct intel_dsb_buffer *dsb_buf)\n \n void intel_dsb_buffer_flush_map(struct intel_dsb_buffer *dsb_buf)\n {\n+\tstruct xe_device *xe = dsb_buf->vma->bo->tile->xe;\n+\n \t/*\n \t * The memory barrier here is to ensure coherency of DSB vs MMIO,\n \t * both for weak ordering archs and discrete cards.\n \t */\n-\txe_device_wmb(dsb_buf->vma->bo->tile->xe);\n+\txe_device_wmb(xe);\n+\txe_device_l2_flush(xe);\n }\ndiff --git a/drivers/gpu/drm/xe/display/xe_fb_pin.c b/drivers/gpu/drm/xe/display/xe_fb_pin.c\nindex d918ae1c8061..55259969480b 100644\n--- a/drivers/gpu/drm/xe/display/xe_fb_pin.c\n+++ b/drivers/gpu/drm/xe/display/xe_fb_pin.c\n@@ -164,6 +164,9 @@ static int __xe_pin_fb_vma_dpt(const struct intel_framebuffer *fb,\n \n \tvma->dpt = dpt;\n \tvma->node = dpt->ggtt_node[tile0->id];\n+\n+\t/* Ensure DPT writes are flushed */\n+\txe_device_l2_flush(xe);\n \treturn 0;\n }\n \n@@ -333,8 +336,6 @@ static struct i915_vma *__xe_pin_fb_vma(const struct intel_framebuffer *fb,\n \tif (ret)\n \t\tgoto err_unpin;\n \n-\t/* Ensure DPT writes are flushed */\n-\txe_device_l2_flush(xe);\n \treturn vma;\n \n err_unpin:\ndiff --git a/drivers/gpu/drm/xe/regs/xe_mchbar_regs.h b/drivers/gpu/drm/xe/regs/xe_mchbar_regs.h\nindex 5394a1373a6b..ef2bf984723f 100644\n--- a/drivers/gpu/drm/xe/regs/xe_mchbar_regs.h\n+++ b/drivers/gpu/drm/xe/regs/xe_mchbar_regs.h\n@@ -40,6 +40,7 @@\n #define PCU_CR_PACKAGE_RAPL_LIMIT\t\tXE_REG(MCHBAR_MIRROR_BASE_SNB + 0x59a0)\n #define   PWR_LIM_VAL\t\t\t\tREG_GENMASK(14, 0)\n #define   PWR_LIM_EN\t\t\t\tREG_BIT(15)\n+#define   PWR_LIM\t\t\t\tREG_GENMASK(15, 0)\n #define   PWR_LIM_TIME\t\t\t\tREG_GENMASK(23, 17)\n #define   PWR_LIM_TIME_X\t\t\tREG_GENMASK(23, 22)\n #define   PWR_LIM_TIME_Y\t\t\tREG_GENMASK(21, 17)\ndiff --git a/drivers/gpu/drm/xe/xe_ggtt.c b/drivers/gpu/drm/xe/xe_ggtt.c\nindex 7062115909f2..2c799958c1e4 100644\n--- a/drivers/gpu/drm/xe/xe_ggtt.c\n+++ b/drivers/gpu/drm/xe/xe_ggtt.c\n@@ -201,6 +201,13 @@ static const struct xe_ggtt_pt_ops xelpg_pt_wa_ops = {\n \t.ggtt_set_pte = xe_ggtt_set_pte_and_flush,\n };\n \n+static void dev_fini_ggtt(void *arg)\n+{\n+\tstruct xe_ggtt *ggtt = arg;\n+\n+\tdrain_workqueue(ggtt->wq);\n+}\n+\n /**\n  * xe_ggtt_init_early - Early GGTT initialization\n  * @ggtt: the &xe_ggtt to be initialized\n@@ -257,6 +264,10 @@ int xe_ggtt_init_early(struct xe_ggtt *ggtt)\n \tif (err)\n \t\treturn err;\n \n+\terr = devm_add_action_or_reset(xe->drm.dev, dev_fini_ggtt, ggtt);\n+\tif (err)\n+\t\treturn err;\n+\n \tif (IS_SRIOV_VF(xe)) {\n \t\terr = xe_gt_sriov_vf_prepare_ggtt(xe_tile_get_gt(ggtt->tile, 0));\n \t\tif (err)\ndiff --git a/drivers/gpu/drm/xe/xe_guc_ct.c b/drivers/gpu/drm/xe/xe_guc_ct.c\nindex d0ac48d8f4f7..bbcbb348256f 100644\n--- a/drivers/gpu/drm/xe/xe_guc_ct.c\n+++ b/drivers/gpu/drm/xe/xe_guc_ct.c\n@@ -34,6 +34,11 @@\n #include \"xe_pm.h\"\n #include \"xe_trace_guc.h\"\n \n+static void receive_g2h(struct xe_guc_ct *ct);\n+static void g2h_worker_func(struct work_struct *w);\n+static void safe_mode_worker_func(struct work_struct *w);\n+static void ct_exit_safe_mode(struct xe_guc_ct *ct);\n+\n #if IS_ENABLED(CONFIG_DRM_XE_DEBUG)\n enum {\n \t/* Internal states, not error conditions */\n@@ -186,14 +191,11 @@ static void guc_ct_fini(struct drm_device *drm, void *arg)\n {\n \tstruct xe_guc_ct *ct = arg;\n \n+\tct_exit_safe_mode(ct);\n \tdestroy_workqueue(ct->g2h_wq);\n \txa_destroy(&ct->fence_lookup);\n }\n \n-static void receive_g2h(struct xe_guc_ct *ct);\n-static void g2h_worker_func(struct work_struct *w);\n-static void safe_mode_worker_func(struct work_struct *w);\n-\n static void primelockdep(struct xe_guc_ct *ct)\n {\n \tif (!IS_ENABLED(CONFIG_LOCKDEP))\ndiff --git a/drivers/gpu/drm/xe/xe_hwmon.c b/drivers/gpu/drm/xe/xe_hwmon.c\nindex 74f31639b37f..f008e8049700 100644\n--- a/drivers/gpu/drm/xe/xe_hwmon.c\n+++ b/drivers/gpu/drm/xe/xe_hwmon.c\n@@ -159,8 +159,8 @@ static int xe_hwmon_pcode_read_power_limit(const struct xe_hwmon *hwmon, u32 att\n \treturn ret;\n }\n \n-static int xe_hwmon_pcode_write_power_limit(const struct xe_hwmon *hwmon, u32 attr, u8 channel,\n-\t\t\t\t\t    u32 uval)\n+static int xe_hwmon_pcode_rmw_power_limit(const struct xe_hwmon *hwmon, u32 attr, u8 channel,\n+\t\t\t\t\t  u32 clr, u32 set)\n {\n \tstruct xe_tile *root_tile = xe_device_get_root_tile(hwmon->xe);\n \tu32 val0, val1;\n@@ -179,7 +179,7 @@ static int xe_hwmon_pcode_write_power_limit(const struct xe_hwmon *hwmon, u32 at\n \t\t\tchannel, val0, val1, ret);\n \n \tif (attr == PL1_HWMON_ATTR)\n-\t\tval0 = uval;\n+\t\tval0 = (val0 & ~clr) | set;\n \telse\n \t\treturn -EIO;\n \n@@ -339,7 +339,7 @@ static int xe_hwmon_power_max_write(struct xe_hwmon *hwmon, u32 attr, int channe\n \t\tif (hwmon->xe->info.has_mbx_power_limits) {\n \t\t\tdrm_dbg(&hwmon->xe->drm, \"disabling %s on channel %d\\n\",\n \t\t\t\tPWR_ATTR_TO_STR(attr), channel);\n-\t\t\txe_hwmon_pcode_write_power_limit(hwmon, attr, channel, 0);\n+\t\t\txe_hwmon_pcode_rmw_power_limit(hwmon, attr, channel, PWR_LIM_EN, 0);\n \t\t\txe_hwmon_pcode_read_power_limit(hwmon, attr, channel, &reg_val);\n \t\t} else {\n \t\t\treg_val = xe_mmio_rmw32(mmio, rapl_limit, PWR_LIM_EN, 0);\n@@ -370,10 +370,9 @@ static int xe_hwmon_power_max_write(struct xe_hwmon *hwmon, u32 attr, int channe\n \t}\n \n \tif (hwmon->xe->info.has_mbx_power_limits)\n-\t\tret = xe_hwmon_pcode_write_power_limit(hwmon, attr, channel, reg_val);\n+\t\tret = xe_hwmon_pcode_rmw_power_limit(hwmon, attr, channel, PWR_LIM, reg_val);\n \telse\n-\t\treg_val = xe_mmio_rmw32(mmio, rapl_limit, PWR_LIM_EN | PWR_LIM_VAL,\n-\t\t\t\t\treg_val);\n+\t\treg_val = xe_mmio_rmw32(mmio, rapl_limit, PWR_LIM, reg_val);\n unlock:\n \tmutex_unlock(&hwmon->hwmon_lock);\n \treturn ret;\n@@ -563,14 +562,11 @@ xe_hwmon_power_max_interval_store(struct device *dev, struct device_attribute *a\n \n \tmutex_lock(&hwmon->hwmon_lock);\n \n-\tif (hwmon->xe->info.has_mbx_power_limits) {\n-\t\tret = xe_hwmon_pcode_read_power_limit(hwmon, power_attr, channel, (u32 *)&r);\n-\t\tr = (r & ~PWR_LIM_TIME) | rxy;\n-\t\txe_hwmon_pcode_write_power_limit(hwmon, power_attr, channel, r);\n-\t} else {\n+\tif (hwmon->xe->info.has_mbx_power_limits)\n+\t\txe_hwmon_pcode_rmw_power_limit(hwmon, power_attr, channel, PWR_LIM_TIME, rxy);\n+\telse\n \t\tr = xe_mmio_rmw32(mmio, xe_hwmon_get_reg(hwmon, REG_PKG_RAPL_LIMIT, channel),\n \t\t\t\t  PWR_LIM_TIME, rxy);\n-\t}\n \n \tmutex_unlock(&hwmon->hwmon_lock);\n \n@@ -1138,12 +1134,12 @@ xe_hwmon_get_preregistration_info(struct xe_hwmon *hwmon)\n \t\t} else {\n \t\t\tdrm_info(&hwmon->xe->drm, \"Using mailbox commands for power limits\\n\");\n \t\t\t/* Write default limits to read from pcode from now on. */\n-\t\t\txe_hwmon_pcode_write_power_limit(hwmon, PL1_HWMON_ATTR,\n-\t\t\t\t\t\t\t CHANNEL_CARD,\n-\t\t\t\t\t\t\t hwmon->pl1_on_boot[CHANNEL_CARD]);\n-\t\t\txe_hwmon_pcode_write_power_limit(hwmon, PL1_HWMON_ATTR,\n-\t\t\t\t\t\t\t CHANNEL_PKG,\n-\t\t\t\t\t\t\t hwmon->pl1_on_boot[CHANNEL_PKG]);\n+\t\t\txe_hwmon_pcode_rmw_power_limit(hwmon, PL1_HWMON_ATTR,\n+\t\t\t\t\t\t       CHANNEL_CARD, PWR_LIM | PWR_LIM_TIME,\n+\t\t\t\t\t\t       hwmon->pl1_on_boot[CHANNEL_CARD]);\n+\t\t\txe_hwmon_pcode_rmw_power_limit(hwmon, PL1_HWMON_ATTR,\n+\t\t\t\t\t\t       CHANNEL_PKG, PWR_LIM | PWR_LIM_TIME,\n+\t\t\t\t\t\t       hwmon->pl1_on_boot[CHANNEL_PKG]);\n \t\t\thwmon->scl_shift_power = PWR_UNIT;\n \t\t\thwmon->scl_shift_energy = ENERGY_UNIT;\n \t\t\thwmon->scl_shift_time = TIME_UNIT;",
    "stats": {
      "insertions": 189,
      "deletions": 81,
      "files": 21
    }
  },
  {
    "sha": "26fd9f7b7ff3794c5de0e6ae538cead53118b4c3",
    "message": "Merge tag 'cxl-fixes-6.16-rc4' of git://git.kernel.org/pub/scm/linux/kernel/git/cxl/cxl\n\nPull Compute Express Link (CXL) fixes from Dave Jiang:\n \"These fixes address a few issues in the CXL subsystem, including\n  dealing with some bugs in the CXL EDAC and RAS drivers:\n\n   - Fix return value of cxlctl_validate_set_features()\n\n   - Fix min_scrub_cycle of a region miscaculation and add additional\n     documentation\n\n   - Fix potential memory leak issues for CXL EDAC\n\n   - Fix CPER handler device confusion for CXL RAS\n\n   - Fix using wrong repair type to check DRAM event record\"\n\n* tag 'cxl-fixes-6.16-rc4' of git://git.kernel.org/pub/scm/linux/kernel/git/cxl/cxl:\n  cxl/edac: Fix using wrong repair type to check dram event record\n  cxl/ras: Fix CPER handler device confusion\n  cxl/edac: Fix potential memory leak issues\n  cxl/Documentation: Add more description about min/max scrub cycle\n  cxl/edac: Fix the min_scrub_cycle of a region miscalculation\n  cxl: fix return value in cxlctl_validate_set_features()",
    "author": "Linus Torvalds",
    "date": "2025-06-27T17:58:32-07:00",
    "files_changed": [
      "drivers/cxl/core/edac.c",
      "drivers/cxl/core/features.c",
      "drivers/cxl/core/ras.c"
    ],
    "diff": "diff --git a/Documentation/ABI/testing/sysfs-edac-scrub b/Documentation/ABI/testing/sysfs-edac-scrub\nindex c43be90deab4..ab6014743da5 100644\n--- a/Documentation/ABI/testing/sysfs-edac-scrub\n+++ b/Documentation/ABI/testing/sysfs-edac-scrub\n@@ -49,6 +49,12 @@ Description:\n \t\t(RO) Supported minimum scrub cycle duration in seconds\n \t\tby the memory scrubber.\n \n+\t\tDevice-based scrub: returns the minimum scrub cycle\n+\t\tsupported by the memory device.\n+\n+\t\tRegion-based scrub: returns the max of minimum scrub cycles\n+\t\tsupported by individual memory devices that back the region.\n+\n What:\t\t/sys/bus/edac/devices/<dev-name>/scrubX/max_cycle_duration\n Date:\t\tMarch 2025\n KernelVersion:\t6.15\n@@ -57,6 +63,16 @@ Description:\n \t\t(RO) Supported maximum scrub cycle duration in seconds\n \t\tby the memory scrubber.\n \n+\t\tDevice-based scrub: returns the maximum scrub cycle supported\n+\t\tby the memory device.\n+\n+\t\tRegion-based scrub: returns the min of maximum scrub cycles\n+\t\tsupported by individual memory devices that back the region.\n+\n+\t\tIf the memory device does not provide maximum scrub cycle\n+\t\tinformation, return the maximum supported value of the scrub\n+\t\tcycle field.\n+\n What:\t\t/sys/bus/edac/devices/<dev-name>/scrubX/current_cycle_duration\n Date:\t\tMarch 2025\n KernelVersion:\t6.15\ndiff --git a/drivers/cxl/core/edac.c b/drivers/cxl/core/edac.c\nindex 2cbc664e5d62..623aaa4439c4 100644\n--- a/drivers/cxl/core/edac.c\n+++ b/drivers/cxl/core/edac.c\n@@ -103,10 +103,10 @@ static int cxl_scrub_get_attrbs(struct cxl_patrol_scrub_context *cxl_ps_ctx,\n \t\t\t\tu8 *cap, u16 *cycle, u8 *flags, u8 *min_cycle)\n {\n \tstruct cxl_mailbox *cxl_mbox;\n-\tu8 min_scrub_cycle = U8_MAX;\n \tstruct cxl_region_params *p;\n \tstruct cxl_memdev *cxlmd;\n \tstruct cxl_region *cxlr;\n+\tu8 min_scrub_cycle = 0;\n \tint i, ret;\n \n \tif (!cxl_ps_ctx->cxlr) {\n@@ -133,8 +133,12 @@ static int cxl_scrub_get_attrbs(struct cxl_patrol_scrub_context *cxl_ps_ctx,\n \t\tif (ret)\n \t\t\treturn ret;\n \n+\t\t/*\n+\t\t * The min_scrub_cycle of a region is the max of minimum scrub\n+\t\t * cycles supported by memdevs that back the region.\n+\t\t */\n \t\tif (min_cycle)\n-\t\t\tmin_scrub_cycle = min(*min_cycle, min_scrub_cycle);\n+\t\t\tmin_scrub_cycle = max(*min_cycle, min_scrub_cycle);\n \t}\n \n \tif (min_cycle)\n@@ -1099,8 +1103,10 @@ int cxl_store_rec_gen_media(struct cxl_memdev *cxlmd, union cxl_event *evt)\n \told_rec = xa_store(&array_rec->rec_gen_media,\n \t\t\t   le64_to_cpu(rec->media_hdr.phys_addr), rec,\n \t\t\t   GFP_KERNEL);\n-\tif (xa_is_err(old_rec))\n+\tif (xa_is_err(old_rec)) {\n+\t\tkfree(rec);\n \t\treturn xa_err(old_rec);\n+\t}\n \n \tkfree(old_rec);\n \n@@ -1127,8 +1133,10 @@ int cxl_store_rec_dram(struct cxl_memdev *cxlmd, union cxl_event *evt)\n \told_rec = xa_store(&array_rec->rec_dram,\n \t\t\t   le64_to_cpu(rec->media_hdr.phys_addr), rec,\n \t\t\t   GFP_KERNEL);\n-\tif (xa_is_err(old_rec))\n+\tif (xa_is_err(old_rec)) {\n+\t\tkfree(rec);\n \t\treturn xa_err(old_rec);\n+\t}\n \n \tkfree(old_rec);\n \n@@ -1315,7 +1323,7 @@ cxl_mem_get_rec_dram(struct cxl_memdev *cxlmd,\n \t\tattrbs.bank = ctx->bank;\n \tbreak;\n \tcase EDAC_REPAIR_RANK_SPARING:\n-\t\tattrbs.repair_type = CXL_BANK_SPARING;\n+\t\tattrbs.repair_type = CXL_RANK_SPARING;\n \t\tbreak;\n \tdefault:\n \t\treturn NULL;\ndiff --git a/drivers/cxl/core/features.c b/drivers/cxl/core/features.c\nindex 6f2eae1eb126..7c750599ea69 100644\n--- a/drivers/cxl/core/features.c\n+++ b/drivers/cxl/core/features.c\n@@ -544,7 +544,7 @@ static bool cxlctl_validate_set_features(struct cxl_features_state *cxlfs,\n \tu32 flags;\n \n \tif (rpc_in->op_size < sizeof(uuid_t))\n-\t\treturn ERR_PTR(-EINVAL);\n+\t\treturn false;\n \n \tfeat = cxl_feature_info(cxlfs, &rpc_in->set_feat_in.uuid);\n \tif (IS_ERR(feat))\ndiff --git a/drivers/cxl/core/ras.c b/drivers/cxl/core/ras.c\nindex 485a831695c7..2731ba3a0799 100644\n--- a/drivers/cxl/core/ras.c\n+++ b/drivers/cxl/core/ras.c\n@@ -31,40 +31,38 @@ static void cxl_cper_trace_uncorr_port_prot_err(struct pci_dev *pdev,\n \t\t\t\t\t       ras_cap.header_log);\n }\n \n-static void cxl_cper_trace_corr_prot_err(struct pci_dev *pdev,\n-\t\t\t\t  struct cxl_ras_capability_regs ras_cap)\n+static void cxl_cper_trace_corr_prot_err(struct cxl_memdev *cxlmd,\n+\t\t\t\t\t struct cxl_ras_capability_regs ras_cap)\n {\n \tu32 status = ras_cap.cor_status & ~ras_cap.cor_mask;\n-\tstruct cxl_dev_state *cxlds;\n \n-\tcxlds = pci_get_drvdata(pdev);\n-\tif (!cxlds)\n-\t\treturn;\n-\n-\ttrace_cxl_aer_correctable_error(cxlds->cxlmd, status);\n+\ttrace_cxl_aer_correctable_error(cxlmd, status);\n }\n \n-static void cxl_cper_trace_uncorr_prot_err(struct pci_dev *pdev,\n-\t\t\t\t    struct cxl_ras_capability_regs ras_cap)\n+static void\n+cxl_cper_trace_uncorr_prot_err(struct cxl_memdev *cxlmd,\n+\t\t\t       struct cxl_ras_capability_regs ras_cap)\n {\n \tu32 status = ras_cap.uncor_status & ~ras_cap.uncor_mask;\n-\tstruct cxl_dev_state *cxlds;\n \tu32 fe;\n \n-\tcxlds = pci_get_drvdata(pdev);\n-\tif (!cxlds)\n-\t\treturn;\n-\n \tif (hweight32(status) > 1)\n \t\tfe = BIT(FIELD_GET(CXL_RAS_CAP_CONTROL_FE_MASK,\n \t\t\t\t   ras_cap.cap_control));\n \telse\n \t\tfe = status;\n \n-\ttrace_cxl_aer_uncorrectable_error(cxlds->cxlmd, status, fe,\n+\ttrace_cxl_aer_uncorrectable_error(cxlmd, status, fe,\n \t\t\t\t\t  ras_cap.header_log);\n }\n \n+static int match_memdev_by_parent(struct device *dev, const void *uport)\n+{\n+\tif (is_cxl_memdev(dev) && dev->parent == uport)\n+\t\treturn 1;\n+\treturn 0;\n+}\n+\n static void cxl_cper_handle_prot_err(struct cxl_cper_prot_err_work_data *data)\n {\n \tunsigned int devfn = PCI_DEVFN(data->prot_err.agent_addr.device,\n@@ -73,13 +71,12 @@ static void cxl_cper_handle_prot_err(struct cxl_cper_prot_err_work_data *data)\n \t\tpci_get_domain_bus_and_slot(data->prot_err.agent_addr.segment,\n \t\t\t\t\t    data->prot_err.agent_addr.bus,\n \t\t\t\t\t    devfn);\n+\tstruct cxl_memdev *cxlmd;\n \tint port_type;\n \n \tif (!pdev)\n \t\treturn;\n \n-\tguard(device)(&pdev->dev);\n-\n \tport_type = pci_pcie_type(pdev);\n \tif (port_type == PCI_EXP_TYPE_ROOT_PORT ||\n \t    port_type == PCI_EXP_TYPE_DOWNSTREAM ||\n@@ -92,10 +89,20 @@ static void cxl_cper_handle_prot_err(struct cxl_cper_prot_err_work_data *data)\n \t\treturn;\n \t}\n \n+\tguard(device)(&pdev->dev);\n+\tif (!pdev->dev.driver)\n+\t\treturn;\n+\n+\tstruct device *mem_dev __free(put_device) = bus_find_device(\n+\t\t&cxl_bus_type, NULL, pdev, match_memdev_by_parent);\n+\tif (!mem_dev)\n+\t\treturn;\n+\n+\tcxlmd = to_cxl_memdev(mem_dev);\n \tif (data->severity == AER_CORRECTABLE)\n-\t\tcxl_cper_trace_corr_prot_err(pdev, data->ras_cap);\n+\t\tcxl_cper_trace_corr_prot_err(cxlmd, data->ras_cap);\n \telse\n-\t\tcxl_cper_trace_uncorr_prot_err(pdev, data->ras_cap);\n+\t\tcxl_cper_trace_uncorr_prot_err(cxlmd, data->ras_cap);\n }\n \n static void cxl_cper_prot_err_work_fn(struct work_struct *work)",
    "stats": {
      "insertions": 57,
      "deletions": 26,
      "files": 4
    }
  },
  {
    "sha": "2def09ead4ad5907988b655d1e1454003aaf8297",
    "message": "dpaa2-eth: fix xdp_rxq_info leak\n\nThe driver registered xdp_rxq_info structures via xdp_rxq_info_reg()\nbut failed to properly unregister them in error paths and during\nremoval.\n\nFixes: d678be1dc1ec (\"dpaa2-eth: add XDP_REDIRECT support\")\nSigned-off-by: Fushuai Wang <wangfushuai@baidu.com>\nReviewed-by: Simon Horman <horms@kernel.org>\nReviewed-by: Ioana Ciornei <ioana.ciornei@nxp.com>\nLink: https://patch.msgid.link/20250626133003.80136-1-wangfushuai@baidu.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>",
    "author": "Fushuai Wang",
    "date": "2025-06-27T17:11:10-07:00",
    "files_changed": [
      "drivers/net/ethernet/freescale/dpaa2/dpaa2-eth.c"
    ],
    "diff": "diff --git a/drivers/net/ethernet/freescale/dpaa2/dpaa2-eth.c b/drivers/net/ethernet/freescale/dpaa2/dpaa2-eth.c\nindex 2ec2c3dab250..b82f121cadad 100644\n--- a/drivers/net/ethernet/freescale/dpaa2/dpaa2-eth.c\n+++ b/drivers/net/ethernet/freescale/dpaa2/dpaa2-eth.c\n@@ -3939,6 +3939,7 @@ static int dpaa2_eth_setup_rx_flow(struct dpaa2_eth_priv *priv,\n \t\t\t\t\t MEM_TYPE_PAGE_ORDER0, NULL);\n \tif (err) {\n \t\tdev_err(dev, \"xdp_rxq_info_reg_mem_model failed\\n\");\n+\t\txdp_rxq_info_unreg(&fq->channel->xdp_rxq);\n \t\treturn err;\n \t}\n \n@@ -4432,17 +4433,25 @@ static int dpaa2_eth_bind_dpni(struct dpaa2_eth_priv *priv)\n \t\t\treturn -EINVAL;\n \t\t}\n \t\tif (err)\n-\t\t\treturn err;\n+\t\t\tgoto out;\n \t}\n \n \terr = dpni_get_qdid(priv->mc_io, 0, priv->mc_token,\n \t\t\t    DPNI_QUEUE_TX, &priv->tx_qdid);\n \tif (err) {\n \t\tdev_err(dev, \"dpni_get_qdid() failed\\n\");\n-\t\treturn err;\n+\t\tgoto out;\n \t}\n \n \treturn 0;\n+\n+out:\n+\twhile (i--) {\n+\t\tif (priv->fq[i].type == DPAA2_RX_FQ &&\n+\t\t    xdp_rxq_info_is_reg(&priv->fq[i].channel->xdp_rxq))\n+\t\t\txdp_rxq_info_unreg(&priv->fq[i].channel->xdp_rxq);\n+\t}\n+\treturn err;\n }\n \n /* Allocate rings for storing incoming frame descriptors */\n@@ -4825,6 +4834,17 @@ static void dpaa2_eth_del_ch_napi(struct dpaa2_eth_priv *priv)\n \t}\n }\n \n+static void dpaa2_eth_free_rx_xdp_rxq(struct dpaa2_eth_priv *priv)\n+{\n+\tint i;\n+\n+\tfor (i = 0; i < priv->num_fqs; i++) {\n+\t\tif (priv->fq[i].type == DPAA2_RX_FQ &&\n+\t\t    xdp_rxq_info_is_reg(&priv->fq[i].channel->xdp_rxq))\n+\t\t\txdp_rxq_info_unreg(&priv->fq[i].channel->xdp_rxq);\n+\t}\n+}\n+\n static int dpaa2_eth_probe(struct fsl_mc_device *dpni_dev)\n {\n \tstruct device *dev;\n@@ -5028,6 +5048,7 @@ static int dpaa2_eth_probe(struct fsl_mc_device *dpni_dev)\n \tfree_percpu(priv->percpu_stats);\n err_alloc_percpu_stats:\n \tdpaa2_eth_del_ch_napi(priv);\n+\tdpaa2_eth_free_rx_xdp_rxq(priv);\n err_bind:\n \tdpaa2_eth_free_dpbps(priv);\n err_dpbp_setup:\n@@ -5080,6 +5101,7 @@ static void dpaa2_eth_remove(struct fsl_mc_device *ls_dev)\n \tfree_percpu(priv->percpu_extras);\n \n \tdpaa2_eth_del_ch_napi(priv);\n+\tdpaa2_eth_free_rx_xdp_rxq(priv);\n \tdpaa2_eth_free_dpbps(priv);\n \tdpaa2_eth_free_dpio(priv);\n \tdpaa2_eth_free_dpni(priv);",
    "stats": {
      "insertions": 24,
      "deletions": 2,
      "files": 1
    }
  },
  {
    "sha": "6921d1e07cb5eddec830801087b419194fde0803",
    "message": "tracing: Fix filter logic error\n\nIf the processing of the tr->events loop fails, the filter that has been\nadded to filter_head will be released twice in free_filter_list(&head->rcu)\nand __free_filter(filter).\n\nAfter adding the filter of tr->events, add the filter to the filter_head\nprocess to avoid triggering uaf.\n\nLink: https://lore.kernel.org/tencent_4EF87A626D702F816CD0951CE956EC32CD0A@qq.com\nFixes: a9d0aab5eb33 (\"tracing: Fix regression of filter waiting a long time on RCU synchronization\")\nReported-by: syzbot+daba72c4af9915e9c894@syzkaller.appspotmail.com\nCloses: https://syzkaller.appspot.com/bug?extid=daba72c4af9915e9c894\nTested-by: syzbot+daba72c4af9915e9c894@syzkaller.appspotmail.com\nAcked-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\nSigned-off-by: Edward Adam Davis <eadavis@qq.com>\nSigned-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>",
    "author": "Edward Adam Davis",
    "date": "2025-06-27T15:51:36-04:00",
    "files_changed": [
      "kernel/trace/trace_events_filter.c"
    ],
    "diff": "diff --git a/kernel/trace/trace_events_filter.c b/kernel/trace/trace_events_filter.c\nindex 08141f105c95..3885aadc434d 100644\n--- a/kernel/trace/trace_events_filter.c\n+++ b/kernel/trace/trace_events_filter.c\n@@ -1436,13 +1436,6 @@ static void filter_free_subsystem_filters(struct trace_subsystem_dir *dir,\n \n \tINIT_LIST_HEAD(&head->list);\n \n-\titem = kmalloc(sizeof(*item), GFP_KERNEL);\n-\tif (!item)\n-\t\tgoto free_now;\n-\n-\titem->filter = filter;\n-\tlist_add_tail(&item->list, &head->list);\n-\n \tlist_for_each_entry(file, &tr->events, list) {\n \t\tif (file->system != dir)\n \t\t\tcontinue;\n@@ -1454,6 +1447,13 @@ static void filter_free_subsystem_filters(struct trace_subsystem_dir *dir,\n \t\tevent_clear_filter(file);\n \t}\n \n+\titem = kmalloc(sizeof(*item), GFP_KERNEL);\n+\tif (!item)\n+\t\tgoto free_now;\n+\n+\titem->filter = filter;\n+\tlist_add_tail(&item->list, &head->list);\n+\n \tdelay_free_filter(head);\n \treturn;\n  free_now:",
    "stats": {
      "insertions": 7,
      "deletions": 7,
      "files": 1
    }
  }
]