[
  {
    "sha": "7544f3f5b0b58c396f374d060898b5939da31709",
    "message": "bridge: mcast: Fix use-after-free during router port configuration\n\nThe bridge maintains a global list of ports behind which a multicast\nrouter resides. The list is consulted during forwarding to ensure\nmulticast packets are forwarded to these ports even if the ports are not\nmember in the matching MDB entry.\n\nWhen per-VLAN multicast snooping is enabled, the per-port multicast\ncontext is disabled on each port and the port is removed from the global\nrouter port list:\n\n # ip link add name br1 up type bridge vlan_filtering 1 mcast_snooping 1\n # ip link add name dummy1 up master br1 type dummy\n # ip link set dev dummy1 type bridge_slave mcast_router 2\n $ bridge -d mdb show | grep router\n router ports on br1: dummy1\n # ip link set dev br1 type bridge mcast_vlan_snooping 1\n $ bridge -d mdb show | grep router\n\nHowever, the port can be re-added to the global list even when per-VLAN\nmulticast snooping is enabled:\n\n # ip link set dev dummy1 type bridge_slave mcast_router 0\n # ip link set dev dummy1 type bridge_slave mcast_router 2\n $ bridge -d mdb show | grep router\n router ports on br1: dummy1\n\nSince commit 4b30ae9adb04 (\"net: bridge: mcast: re-implement\nbr_multicast_{enable, disable}_port functions\"), when per-VLAN multicast\nsnooping is enabled, multicast disablement on a port will disable the\nper-{port, VLAN} multicast contexts and not the per-port one. As a\nresult, a port will remain in the global router port list even after it\nis deleted. This will lead to a use-after-free [1] when the list is\ntraversed (when adding a new port to the list, for example):\n\n # ip link del dev dummy1\n # ip link add name dummy2 up master br1 type dummy\n # ip link set dev dummy2 type bridge_slave mcast_router 2\n\nSimilarly, stale entries can also be found in the per-VLAN router port\nlist. When per-VLAN multicast snooping is disabled, the per-{port, VLAN}\ncontexts are disabled on each port and the port is removed from the\nper-VLAN router port list:\n\n # ip link add name br1 up type bridge vlan_filtering 1 mcast_snooping 1 mcast_vlan_snooping 1\n # ip link add name dummy1 up master br1 type dummy\n # bridge vlan add vid 2 dev dummy1\n # bridge vlan global set vid 2 dev br1 mcast_snooping 1\n # bridge vlan set vid 2 dev dummy1 mcast_router 2\n $ bridge vlan global show dev br1 vid 2 | grep router\n       router ports: dummy1\n # ip link set dev br1 type bridge mcast_vlan_snooping 0\n $ bridge vlan global show dev br1 vid 2 | grep router\n\nHowever, the port can be re-added to the per-VLAN list even when\nper-VLAN multicast snooping is disabled:\n\n # bridge vlan set vid 2 dev dummy1 mcast_router 0\n # bridge vlan set vid 2 dev dummy1 mcast_router 2\n $ bridge vlan global show dev br1 vid 2 | grep router\n       router ports: dummy1\n\nWhen the VLAN is deleted from the port, the per-{port, VLAN} multicast\ncontext will not be disabled since multicast snooping is not enabled\non the VLAN. As a result, the port will remain in the per-VLAN router\nport list even after it is no longer member in the VLAN. This will lead\nto a use-after-free [2] when the list is traversed (when adding a new\nport to the list, for example):\n\n # ip link add name dummy2 up master br1 type dummy\n # bridge vlan add vid 2 dev dummy2\n # bridge vlan del vid 2 dev dummy1\n # bridge vlan set vid 2 dev dummy2 mcast_router 2\n\nFix these issues by removing the port from the relevant (global or\nper-VLAN) router port list in br_multicast_port_ctx_deinit(). The\nfunction is invoked during port deletion with the per-port multicast\ncontext and during VLAN deletion with the per-{port, VLAN} multicast\ncontext.\n\nNote that deleting the multicast router timer is not enough as it only\ntakes care of the temporary multicast router states (1 or 3) and not the\npermanent one (2).\n\n[1]\nBUG: KASAN: slab-out-of-bounds in br_multicast_add_router.part.0+0x3f1/0x560\nWrite of size 8 at addr ffff888004a67328 by task ip/384\n[...]\nCall Trace:\n <TASK>\n dump_stack_lvl+0x6f/0xa0\n print_address_description.constprop.0+0x6f/0x350\n print_report+0x108/0x205\n kasan_report+0xdf/0x110\n br_multicast_add_router.part.0+0x3f1/0x560\n br_multicast_set_port_router+0x74e/0xac0\n br_setport+0xa55/0x1870\n br_port_slave_changelink+0x95/0x120\n __rtnl_newlink+0x5e8/0xa40\n rtnl_newlink+0x627/0xb00\n rtnetlink_rcv_msg+0x6fb/0xb70\n netlink_rcv_skb+0x11f/0x350\n netlink_unicast+0x426/0x710\n netlink_sendmsg+0x75a/0xc20\n __sock_sendmsg+0xc1/0x150\n ____sys_sendmsg+0x5aa/0x7b0\n ___sys_sendmsg+0xfc/0x180\n __sys_sendmsg+0x124/0x1c0\n do_syscall_64+0xbb/0x360\n entry_SYSCALL_64_after_hwframe+0x4b/0x53\n\n[2]\nBUG: KASAN: slab-use-after-free in br_multicast_add_router.part.0+0x378/0x560\nRead of size 8 at addr ffff888009f00840 by task bridge/391\n[...]\nCall Trace:\n <TASK>\n dump_stack_lvl+0x6f/0xa0\n print_address_description.constprop.0+0x6f/0x350\n print_report+0x108/0x205\n kasan_report+0xdf/0x110\n br_multicast_add_router.part.0+0x378/0x560\n br_multicast_set_port_router+0x6f9/0xac0\n br_vlan_process_options+0x8b6/0x1430\n br_vlan_rtm_process_one+0x605/0xa30\n br_vlan_rtm_process+0x396/0x4c0\n rtnetlink_rcv_msg+0x2f7/0xb70\n netlink_rcv_skb+0x11f/0x350\n netlink_unicast+0x426/0x710\n netlink_sendmsg+0x75a/0xc20\n __sock_sendmsg+0xc1/0x150\n ____sys_sendmsg+0x5aa/0x7b0\n ___sys_sendmsg+0xfc/0x180\n __sys_sendmsg+0x124/0x1c0\n do_syscall_64+0xbb/0x360\n entry_SYSCALL_64_after_hwframe+0x4b/0x53\n\nFixes: 2796d846d74a (\"net: bridge: vlan: convert mcast router global option to per-vlan entry\")\nFixes: 4b30ae9adb04 (\"net: bridge: mcast: re-implement br_multicast_{enable, disable}_port functions\")\nReported-by: syzbot+7bfa4b72c6a5da128d32@syzkaller.appspotmail.com\nCloses: https://lore.kernel.org/all/684c18bd.a00a0220.279073.000b.GAE@google.com/T/\nSigned-off-by: Ido Schimmel <idosch@nvidia.com>\nLink: https://patch.msgid.link/20250619182228.1656906-1-idosch@nvidia.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>",
    "author": "Ido Schimmel",
    "date": "2025-06-23T18:19:10-07:00",
    "files_changed": [
      "net/bridge/br_multicast.c"
    ],
    "diff": "diff --git a/net/bridge/br_multicast.c b/net/bridge/br_multicast.c\nindex 0224ef3dfec0..1377f31b719c 100644\n--- a/net/bridge/br_multicast.c\n+++ b/net/bridge/br_multicast.c\n@@ -2015,10 +2015,19 @@ void br_multicast_port_ctx_init(struct net_bridge_port *port,\n \n void br_multicast_port_ctx_deinit(struct net_bridge_mcast_port *pmctx)\n {\n+\tstruct net_bridge *br = pmctx->port->br;\n+\tbool del = false;\n+\n #if IS_ENABLED(CONFIG_IPV6)\n \ttimer_delete_sync(&pmctx->ip6_mc_router_timer);\n #endif\n \ttimer_delete_sync(&pmctx->ip4_mc_router_timer);\n+\n+\tspin_lock_bh(&br->multicast_lock);\n+\tdel |= br_ip6_multicast_rport_del(pmctx);\n+\tdel |= br_ip4_multicast_rport_del(pmctx);\n+\tbr_multicast_rport_del_notify(pmctx, del);\n+\tspin_unlock_bh(&br->multicast_lock);\n }\n \n int br_multicast_add_port(struct net_bridge_port *port)",
    "stats": {
      "insertions": 9,
      "deletions": 0,
      "files": 1
    }
  },
  {
    "sha": "78f4e737a53e1163ded2687a922fce138aee73f5",
    "message": "Merge tag 'for-6.16/dm-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/device-mapper/linux-dm\n\nPull device mapper fixes from Mikulas Patocka:\n\n - dm-crypt: fix a crash on 32-bit machines\n\n - dm-raid: replace \"rdev\" with correct loop variable name \"r\"\n\n* tag 'for-6.16/dm-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/device-mapper/linux-dm:\n  dm-raid: fix variable in journal device check\n  dm-crypt: Extend state buffer size in crypt_iv_lmk_one",
    "author": "Linus Torvalds",
    "date": "2025-06-23T15:02:57-07:00",
    "files_changed": [
      "drivers/md/dm-crypt.c",
      "drivers/md/dm-raid.c",
      "include/crypto/hash.h",
      "include/crypto/md5.h"
    ],
    "diff": "diff --git a/drivers/md/dm-crypt.c b/drivers/md/dm-crypt.c\nindex 9dfdb63220d7..17157c4216a5 100644\n--- a/drivers/md/dm-crypt.c\n+++ b/drivers/md/dm-crypt.c\n@@ -517,7 +517,10 @@ static int crypt_iv_lmk_one(struct crypt_config *cc, u8 *iv,\n {\n \tstruct iv_lmk_private *lmk = &cc->iv_gen_private.lmk;\n \tSHASH_DESC_ON_STACK(desc, lmk->hash_tfm);\n-\tstruct md5_state md5state;\n+\tunion {\n+\t\tstruct md5_state md5state;\n+\t\tu8 state[CRYPTO_MD5_STATESIZE];\n+\t} u;\n \t__le32 buf[4];\n \tint i, r;\n \n@@ -548,13 +551,13 @@ static int crypt_iv_lmk_one(struct crypt_config *cc, u8 *iv,\n \t\treturn r;\n \n \t/* No MD5 padding here */\n-\tr = crypto_shash_export(desc, &md5state);\n+\tr = crypto_shash_export(desc, &u.md5state);\n \tif (r)\n \t\treturn r;\n \n \tfor (i = 0; i < MD5_HASH_WORDS; i++)\n-\t\t__cpu_to_le32s(&md5state.hash[i]);\n-\tmemcpy(iv, &md5state.hash, cc->iv_size);\n+\t\t__cpu_to_le32s(&u.md5state.hash[i]);\n+\tmemcpy(iv, &u.md5state.hash, cc->iv_size);\n \n \treturn 0;\n }\ndiff --git a/drivers/md/dm-raid.c b/drivers/md/dm-raid.c\nindex d296770478b2..e8c0a8c6fb51 100644\n--- a/drivers/md/dm-raid.c\n+++ b/drivers/md/dm-raid.c\n@@ -2407,7 +2407,7 @@ static int super_init_validation(struct raid_set *rs, struct md_rdev *rdev)\n \t */\n \tsb_retrieve_failed_devices(sb, failed_devices);\n \trdev_for_each(r, mddev) {\n-\t\tif (test_bit(Journal, &rdev->flags) ||\n+\t\tif (test_bit(Journal, &r->flags) ||\n \t\t    !r->sb_page)\n \t\t\tcontinue;\n \t\tsb2 = page_address(r->sb_page);\ndiff --git a/include/crypto/hash.h b/include/crypto/hash.h\nindex 6f6b9de12cd3..db294d452e8c 100644\n--- a/include/crypto/hash.h\n+++ b/include/crypto/hash.h\n@@ -202,6 +202,8 @@ struct shash_desc {\n #define HASH_REQUEST_CLONE(name, gfp) \\\n \thash_request_clone(name, sizeof(__##name##_req), gfp)\n \n+#define CRYPTO_HASH_STATESIZE(coresize, blocksize) (coresize + blocksize + 1)\n+\n /**\n  * struct shash_alg - synchronous message digest definition\n  * @init: see struct ahash_alg\ndiff --git a/include/crypto/md5.h b/include/crypto/md5.h\nindex 198b5d69b92f..28ee533a0507 100644\n--- a/include/crypto/md5.h\n+++ b/include/crypto/md5.h\n@@ -2,6 +2,7 @@\n #ifndef _CRYPTO_MD5_H\n #define _CRYPTO_MD5_H\n \n+#include <crypto/hash.h>\n #include <linux/types.h>\n \n #define MD5_DIGEST_SIZE\t\t16\n@@ -15,6 +16,9 @@\n #define MD5_H2\t0x98badcfeUL\n #define MD5_H3\t0x10325476UL\n \n+#define CRYPTO_MD5_STATESIZE \\\n+\tCRYPTO_HASH_STATESIZE(MD5_STATE_SIZE, MD5_HMAC_BLOCK_SIZE)\n+\n extern const u8 md5_zero_message_hash[MD5_DIGEST_SIZE];\n \n struct md5_state {",
    "stats": {
      "insertions": 14,
      "deletions": 5,
      "files": 4
    }
  },
  {
    "sha": "2b8be57fa0c88ac824a906f29c04d728f9f6047a",
    "message": "Revert \"PCI/ACPI: Fix allocated memory release on error in pci_acpi_scan_root()\"\n\nThis reverts commit 631b2af2f357 (\"PCI/ACPI: Fix allocated memory release\non error in pci_acpi_scan_root()\").\n\nThe reverted patch causes the 'ri->cfg' and 'root_ops' resources to be\nreleased multiple times.\n\nWhen acpi_pci_root_create() fails, these resources have already been\nreleased internally by the __acpi_pci_root_release_info() function.\n\nReleasing them again in pci_acpi_scan_root() leads to incorrect behavior\nand potential memory issues.\n\nWe plan to resolve the issue using a more appropriate fix.\n\nReported-by: Dan Carpenter <dan.carpenter@linaro.org>\nCloses: https://lore.kernel.org/all/aEmdnuw715btq7Q5@stanley.mountain/\nSigned-off-by: Zhe Qiao <qiaozhe@iscas.ac.cn>\nAcked-by: Dan Carpenter <dan.carpenter@linaro.org>\nLink: https://patch.msgid.link/20250619072608.2075475-1-qiaozhe@iscas.ac.cn\nSigned-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>",
    "author": "Zhe Qiao",
    "date": "2025-06-23T22:15:45+02:00",
    "files_changed": [
      "drivers/pci/pci-acpi.c"
    ],
    "diff": "diff --git a/drivers/pci/pci-acpi.c b/drivers/pci/pci-acpi.c\nindex b78e0e417324..af370628e583 100644\n--- a/drivers/pci/pci-acpi.c\n+++ b/drivers/pci/pci-acpi.c\n@@ -1676,19 +1676,24 @@ struct pci_bus *pci_acpi_scan_root(struct acpi_pci_root *root)\n \t\treturn NULL;\n \n \troot_ops = kzalloc(sizeof(*root_ops), GFP_KERNEL);\n-\tif (!root_ops)\n-\t\tgoto free_ri;\n+\tif (!root_ops) {\n+\t\tkfree(ri);\n+\t\treturn NULL;\n+\t}\n \n \tri->cfg = pci_acpi_setup_ecam_mapping(root);\n-\tif (!ri->cfg)\n-\t\tgoto free_root_ops;\n+\tif (!ri->cfg) {\n+\t\tkfree(ri);\n+\t\tkfree(root_ops);\n+\t\treturn NULL;\n+\t}\n \n \troot_ops->release_info = pci_acpi_generic_release_info;\n \troot_ops->prepare_resources = pci_acpi_root_prepare_resources;\n \troot_ops->pci_ops = (struct pci_ops *)&ri->cfg->ops->pci_ops;\n \tbus = acpi_pci_root_create(root, root_ops, &ri->common, ri->cfg);\n \tif (!bus)\n-\t\tgoto free_cfg;\n+\t\treturn NULL;\n \n \t/* If we must preserve the resource configuration, claim now */\n \thost = pci_find_host_bridge(bus);\n@@ -1705,14 +1710,6 @@ struct pci_bus *pci_acpi_scan_root(struct acpi_pci_root *root)\n \t\tpcie_bus_configure_settings(child);\n \n \treturn bus;\n-\n-free_cfg:\n-\tpci_ecam_free(ri->cfg);\n-free_root_ops:\n-\tkfree(root_ops);\n-free_ri:\n-\tkfree(ri);\n-\treturn NULL;\n }\n \n void pcibios_add_bus(struct pci_bus *bus)",
    "stats": {
      "insertions": 10,
      "deletions": 13,
      "files": 1
    }
  },
  {
    "sha": "5ca7fe213ba3113dde19c4cd46347c16d9e69f81",
    "message": "Merge tag 'for-6.16-rc3-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux\n\nPull btrfs fixes from David Sterba:\n \"Fixes:\n\n   - fix invalid inode pointer dereferences during log replay\n\n   - fix a race between renames and directory logging\n\n   - fix shutting down delayed iput worker\n\n   - fix device byte accounting when dropping chunk\n\n   - in zoned mode, fix offset calculations for DUP profile when\n     conventional and sequential zones are used together\n\n  Regression fixes:\n\n   - fix possible double unlock of extent buffer tree (xarray\n     conversion)\n\n   - in zoned mode, fix extent buffer refcount when writing out extents\n     (xarray conversion)\n\n  Error handling fixes and updates:\n\n   - handle unexpected extent type when replaying log\n\n   - check and warn if there are remaining delayed inodes when putting a\n     root\n\n   - fix assertion when building free space tree\n\n   - handle csum tree error with mount option 'rescue=ibadroot'\n\n  Other:\n\n   - error message updates: add prefix to all scrub related messages,\n     include other information in messages\"\n\n* tag 'for-6.16-rc3-tag' of git://git.kernel.org/pub/scm/linux/kernel/git/kdave/linux:\n  btrfs: zoned: fix alloc_offset calculation for partly conventional block groups\n  btrfs: handle csum tree error with rescue=ibadroots correctly\n  btrfs: fix race between async reclaim worker and close_ctree()\n  btrfs: fix assertion when building free space tree\n  btrfs: don't silently ignore unexpected extent type when replaying log\n  btrfs: fix invalid inode pointer dereferences during log replay\n  btrfs: fix double unlock of buffer_tree xarray when releasing subpage eb\n  btrfs: update superblock's device bytes_used when dropping chunk\n  btrfs: fix a race between renames and directory logging\n  btrfs: scrub: add prefix for the error messages\n  btrfs: warn if leaking delayed_nodes in btrfs_put_root()\n  btrfs: fix delayed ref refcount leak in debug assertion\n  btrfs: include root in error message when unlinking inode\n  btrfs: don't drop a reference if btrfs_check_write_meta_pointer() fails",
    "author": "Linus Torvalds",
    "date": "2025-06-23T11:16:38-07:00",
    "files_changed": [
      "fs/btrfs/delayed-inode.c",
      "fs/btrfs/disk-io.c",
      "fs/btrfs/extent_io.c",
      "fs/btrfs/free-space-tree.c",
      "fs/btrfs/inode.c",
      "fs/btrfs/ioctl.c",
      "fs/btrfs/scrub.c",
      "fs/btrfs/tree-log.c",
      "fs/btrfs/volumes.c",
      "fs/btrfs/zoned.c"
    ],
    "diff": "diff --git a/fs/btrfs/delayed-inode.c b/fs/btrfs/delayed-inode.c\nindex c7cc24a5dd5e..8c597fa60523 100644\n--- a/fs/btrfs/delayed-inode.c\n+++ b/fs/btrfs/delayed-inode.c\n@@ -1377,7 +1377,10 @@ static int btrfs_wq_run_delayed_node(struct btrfs_delayed_root *delayed_root,\n \n void btrfs_assert_delayed_root_empty(struct btrfs_fs_info *fs_info)\n {\n-\tWARN_ON(btrfs_first_delayed_node(fs_info->delayed_root));\n+\tstruct btrfs_delayed_node *node = btrfs_first_delayed_node(fs_info->delayed_root);\n+\n+\tif (WARN_ON(node))\n+\t\trefcount_dec(&node->refs);\n }\n \n static bool could_end_wait(struct btrfs_delayed_root *delayed_root, int seq)\ndiff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c\nindex 1beb9458f622..0d6ad7512f21 100644\n--- a/fs/btrfs/disk-io.c\n+++ b/fs/btrfs/disk-io.c\n@@ -1835,6 +1835,8 @@ void btrfs_put_root(struct btrfs_root *root)\n \tif (refcount_dec_and_test(&root->refs)) {\n \t\tif (WARN_ON(!xa_empty(&root->inodes)))\n \t\t\txa_destroy(&root->inodes);\n+\t\tif (WARN_ON(!xa_empty(&root->delayed_nodes)))\n+\t\t\txa_destroy(&root->delayed_nodes);\n \t\tWARN_ON(test_bit(BTRFS_ROOT_DEAD_RELOC_TREE, &root->state));\n \t\tif (root->anon_dev)\n \t\t\tfree_anon_bdev(root->anon_dev);\n@@ -2156,8 +2158,7 @@ static int load_global_roots_objectid(struct btrfs_root *tree_root,\n \t\tfound = true;\n \t\troot = read_tree_root_path(tree_root, path, &key);\n \t\tif (IS_ERR(root)) {\n-\t\t\tif (!btrfs_test_opt(fs_info, IGNOREBADROOTS))\n-\t\t\t\tret = PTR_ERR(root);\n+\t\t\tret = PTR_ERR(root);\n \t\t\tbreak;\n \t\t}\n \t\tset_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);\n@@ -4310,8 +4311,8 @@ void __cold close_ctree(struct btrfs_fs_info *fs_info)\n \t *\n \t * So wait for all ongoing ordered extents to complete and then run\n \t * delayed iputs. This works because once we reach this point no one\n-\t * can either create new ordered extents nor create delayed iputs\n-\t * through some other means.\n+\t * can create new ordered extents, but delayed iputs can still be added\n+\t * by a reclaim worker (see comments further below).\n \t *\n \t * Also note that btrfs_wait_ordered_roots() is not safe here, because\n \t * it waits for BTRFS_ORDERED_COMPLETE to be set on an ordered extent,\n@@ -4322,15 +4323,29 @@ void __cold close_ctree(struct btrfs_fs_info *fs_info)\n \tbtrfs_flush_workqueue(fs_info->endio_write_workers);\n \t/* Ordered extents for free space inodes. */\n \tbtrfs_flush_workqueue(fs_info->endio_freespace_worker);\n+\t/*\n+\t * Run delayed iputs in case an async reclaim worker is waiting for them\n+\t * to be run as mentioned above.\n+\t */\n \tbtrfs_run_delayed_iputs(fs_info);\n-\t/* There should be no more workload to generate new delayed iputs. */\n-\tset_bit(BTRFS_FS_STATE_NO_DELAYED_IPUT, &fs_info->fs_state);\n \n \tcancel_work_sync(&fs_info->async_reclaim_work);\n \tcancel_work_sync(&fs_info->async_data_reclaim_work);\n \tcancel_work_sync(&fs_info->preempt_reclaim_work);\n \tcancel_work_sync(&fs_info->em_shrinker_work);\n \n+\t/*\n+\t * Run delayed iputs again because an async reclaim worker may have\n+\t * added new ones if it was flushing delalloc:\n+\t *\n+\t * shrink_delalloc() -> btrfs_start_delalloc_roots() ->\n+\t *    start_delalloc_inodes() -> btrfs_add_delayed_iput()\n+\t */\n+\tbtrfs_run_delayed_iputs(fs_info);\n+\n+\t/* There should be no more workload to generate new delayed iputs. */\n+\tset_bit(BTRFS_FS_STATE_NO_DELAYED_IPUT, &fs_info->fs_state);\n+\n \t/* Cancel or finish ongoing discard work */\n \tbtrfs_discard_cleanup(fs_info);\n \ndiff --git a/fs/btrfs/extent_io.c b/fs/btrfs/extent_io.c\nindex 849199768664..1dc931c4937f 100644\n--- a/fs/btrfs/extent_io.c\n+++ b/fs/btrfs/extent_io.c\n@@ -4312,7 +4312,6 @@ static int try_release_subpage_extent_buffer(struct folio *folio)\n \t\t\tspin_unlock(&eb->refs_lock);\n \t\t\tcontinue;\n \t\t}\n-\t\txa_unlock_irq(&fs_info->buffer_tree);\n \n \t\t/*\n \t\t * If tree ref isn't set then we know the ref on this eb is a\n@@ -4329,6 +4328,7 @@ static int try_release_subpage_extent_buffer(struct folio *folio)\n \t\t * check the folio private at the end.  And\n \t\t * release_extent_buffer() will release the refs_lock.\n \t\t */\n+\t\txa_unlock_irq(&fs_info->buffer_tree);\n \t\trelease_extent_buffer(eb);\n \t\txa_lock_irq(&fs_info->buffer_tree);\n \t}\ndiff --git a/fs/btrfs/free-space-tree.c b/fs/btrfs/free-space-tree.c\nindex 0c573d46639a..a3e2a2a81461 100644\n--- a/fs/btrfs/free-space-tree.c\n+++ b/fs/btrfs/free-space-tree.c\n@@ -1115,11 +1115,21 @@ static int populate_free_space_tree(struct btrfs_trans_handle *trans,\n \tret = btrfs_search_slot_for_read(extent_root, &key, path, 1, 0);\n \tif (ret < 0)\n \t\tgoto out_locked;\n-\tASSERT(ret == 0);\n+\t/*\n+\t * If ret is 1 (no key found), it means this is an empty block group,\n+\t * without any extents allocated from it and there's no block group\n+\t * item (key BTRFS_BLOCK_GROUP_ITEM_KEY) located in the extent tree\n+\t * because we are using the block group tree feature, so block group\n+\t * items are stored in the block group tree. It also means there are no\n+\t * extents allocated for block groups with a start offset beyond this\n+\t * block group's end offset (this is the last, highest, block group).\n+\t */\n+\tif (!btrfs_fs_compat_ro(trans->fs_info, BLOCK_GROUP_TREE))\n+\t\tASSERT(ret == 0);\n \n \tstart = block_group->start;\n \tend = block_group->start + block_group->length;\n-\twhile (1) {\n+\twhile (ret == 0) {\n \t\tbtrfs_item_key_to_cpu(path->nodes[0], &key, path->slots[0]);\n \n \t\tif (key.type == BTRFS_EXTENT_ITEM_KEY ||\n@@ -1149,8 +1159,6 @@ static int populate_free_space_tree(struct btrfs_trans_handle *trans,\n \t\tret = btrfs_next_item(extent_root, path);\n \t\tif (ret < 0)\n \t\t\tgoto out_locked;\n-\t\tif (ret)\n-\t\t\tbreak;\n \t}\n \tif (start < end) {\n \t\tret = __add_to_free_space_tree(trans, block_group, path2,\ndiff --git a/fs/btrfs/inode.c b/fs/btrfs/inode.c\nindex c0c778243bf1..26d6ed170a19 100644\n--- a/fs/btrfs/inode.c\n+++ b/fs/btrfs/inode.c\n@@ -4250,9 +4250,9 @@ static int __btrfs_unlink_inode(struct btrfs_trans_handle *trans,\n \n \tret = btrfs_del_inode_ref(trans, root, name, ino, dir_ino, &index);\n \tif (ret) {\n-\t\tbtrfs_info(fs_info,\n-\t\t\t\"failed to delete reference to %.*s, inode %llu parent %llu\",\n-\t\t\tname->len, name->name, ino, dir_ino);\n+\t\tbtrfs_crit(fs_info,\n+\t   \"failed to delete reference to %.*s, root %llu inode %llu parent %llu\",\n+\t\t\t   name->len, name->name, btrfs_root_id(root), ino, dir_ino);\n \t\tbtrfs_abort_transaction(trans, ret);\n \t\tgoto err;\n \t}\n@@ -8059,6 +8059,7 @@ static int btrfs_rename_exchange(struct inode *old_dir,\n \tint ret;\n \tint ret2;\n \tbool need_abort = false;\n+\tbool logs_pinned = false;\n \tstruct fscrypt_name old_fname, new_fname;\n \tstruct fscrypt_str *old_name, *new_name;\n \n@@ -8182,6 +8183,31 @@ static int btrfs_rename_exchange(struct inode *old_dir,\n \tinode_inc_iversion(new_inode);\n \tsimple_rename_timestamp(old_dir, old_dentry, new_dir, new_dentry);\n \n+\tif (old_ino != BTRFS_FIRST_FREE_OBJECTID &&\n+\t    new_ino != BTRFS_FIRST_FREE_OBJECTID) {\n+\t\t/*\n+\t\t * If we are renaming in the same directory (and it's not for\n+\t\t * root entries) pin the log early to prevent any concurrent\n+\t\t * task from logging the directory after we removed the old\n+\t\t * entries and before we add the new entries, otherwise that\n+\t\t * task can sync a log without any entry for the inodes we are\n+\t\t * renaming and therefore replaying that log, if a power failure\n+\t\t * happens after syncing the log, would result in deleting the\n+\t\t * inodes.\n+\t\t *\n+\t\t * If the rename affects two different directories, we want to\n+\t\t * make sure the that there's no log commit that contains\n+\t\t * updates for only one of the directories but not for the\n+\t\t * other.\n+\t\t *\n+\t\t * If we are renaming an entry for a root, we don't care about\n+\t\t * log updates since we called btrfs_set_log_full_commit().\n+\t\t */\n+\t\tbtrfs_pin_log_trans(root);\n+\t\tbtrfs_pin_log_trans(dest);\n+\t\tlogs_pinned = true;\n+\t}\n+\n \tif (old_dentry->d_parent != new_dentry->d_parent) {\n \t\tbtrfs_record_unlink_dir(trans, BTRFS_I(old_dir),\n \t\t\t\t\tBTRFS_I(old_inode), true);\n@@ -8253,30 +8279,23 @@ static int btrfs_rename_exchange(struct inode *old_dir,\n \t\tBTRFS_I(new_inode)->dir_index = new_idx;\n \n \t/*\n-\t * Now pin the logs of the roots. We do it to ensure that no other task\n-\t * can sync the logs while we are in progress with the rename, because\n-\t * that could result in an inconsistency in case any of the inodes that\n-\t * are part of this rename operation were logged before.\n+\t * Do the log updates for all inodes.\n+\t *\n+\t * If either entry is for a root we don't need to update the logs since\n+\t * we've called btrfs_set_log_full_commit() before.\n \t */\n-\tif (old_ino != BTRFS_FIRST_FREE_OBJECTID)\n-\t\tbtrfs_pin_log_trans(root);\n-\tif (new_ino != BTRFS_FIRST_FREE_OBJECTID)\n-\t\tbtrfs_pin_log_trans(dest);\n-\n-\t/* Do the log updates for all inodes. */\n-\tif (old_ino != BTRFS_FIRST_FREE_OBJECTID)\n+\tif (logs_pinned) {\n \t\tbtrfs_log_new_name(trans, old_dentry, BTRFS_I(old_dir),\n \t\t\t\t   old_rename_ctx.index, new_dentry->d_parent);\n-\tif (new_ino != BTRFS_FIRST_FREE_OBJECTID)\n \t\tbtrfs_log_new_name(trans, new_dentry, BTRFS_I(new_dir),\n \t\t\t\t   new_rename_ctx.index, old_dentry->d_parent);\n+\t}\n \n-\t/* Now unpin the logs. */\n-\tif (old_ino != BTRFS_FIRST_FREE_OBJECTID)\n+out_fail:\n+\tif (logs_pinned) {\n \t\tbtrfs_end_log_trans(root);\n-\tif (new_ino != BTRFS_FIRST_FREE_OBJECTID)\n \t\tbtrfs_end_log_trans(dest);\n-out_fail:\n+\t}\n \tret2 = btrfs_end_transaction(trans);\n \tret = ret ? ret : ret2;\n out_notrans:\n@@ -8326,6 +8345,7 @@ static int btrfs_rename(struct mnt_idmap *idmap,\n \tint ret2;\n \tu64 old_ino = btrfs_ino(BTRFS_I(old_inode));\n \tstruct fscrypt_name old_fname, new_fname;\n+\tbool logs_pinned = false;\n \n \tif (btrfs_ino(BTRFS_I(new_dir)) == BTRFS_EMPTY_SUBVOL_DIR_OBJECTID)\n \t\treturn -EPERM;\n@@ -8460,6 +8480,29 @@ static int btrfs_rename(struct mnt_idmap *idmap,\n \tinode_inc_iversion(old_inode);\n \tsimple_rename_timestamp(old_dir, old_dentry, new_dir, new_dentry);\n \n+\tif (old_ino != BTRFS_FIRST_FREE_OBJECTID) {\n+\t\t/*\n+\t\t * If we are renaming in the same directory (and it's not a\n+\t\t * root entry) pin the log to prevent any concurrent task from\n+\t\t * logging the directory after we removed the old entry and\n+\t\t * before we add the new entry, otherwise that task can sync\n+\t\t * a log without any entry for the inode we are renaming and\n+\t\t * therefore replaying that log, if a power failure happens\n+\t\t * after syncing the log, would result in deleting the inode.\n+\t\t *\n+\t\t * If the rename affects two different directories, we want to\n+\t\t * make sure the that there's no log commit that contains\n+\t\t * updates for only one of the directories but not for the\n+\t\t * other.\n+\t\t *\n+\t\t * If we are renaming an entry for a root, we don't care about\n+\t\t * log updates since we called btrfs_set_log_full_commit().\n+\t\t */\n+\t\tbtrfs_pin_log_trans(root);\n+\t\tbtrfs_pin_log_trans(dest);\n+\t\tlogs_pinned = true;\n+\t}\n+\n \tif (old_dentry->d_parent != new_dentry->d_parent)\n \t\tbtrfs_record_unlink_dir(trans, BTRFS_I(old_dir),\n \t\t\t\t\tBTRFS_I(old_inode), true);\n@@ -8524,7 +8567,7 @@ static int btrfs_rename(struct mnt_idmap *idmap,\n \tif (old_inode->i_nlink == 1)\n \t\tBTRFS_I(old_inode)->dir_index = index;\n \n-\tif (old_ino != BTRFS_FIRST_FREE_OBJECTID)\n+\tif (logs_pinned)\n \t\tbtrfs_log_new_name(trans, old_dentry, BTRFS_I(old_dir),\n \t\t\t\t   rename_ctx.index, new_dentry->d_parent);\n \n@@ -8540,6 +8583,10 @@ static int btrfs_rename(struct mnt_idmap *idmap,\n \t\t}\n \t}\n out_fail:\n+\tif (logs_pinned) {\n+\t\tbtrfs_end_log_trans(root);\n+\t\tbtrfs_end_log_trans(dest);\n+\t}\n \tret2 = btrfs_end_transaction(trans);\n \tret = ret ? ret : ret2;\n out_notrans:\ndiff --git a/fs/btrfs/ioctl.c b/fs/btrfs/ioctl.c\nindex 913acef3f0a9..4eda35bdba71 100644\n--- a/fs/btrfs/ioctl.c\n+++ b/fs/btrfs/ioctl.c\n@@ -3139,7 +3139,7 @@ static long btrfs_ioctl_scrub(struct file *file, void __user *arg)\n \t\treturn -EPERM;\n \n \tif (btrfs_fs_incompat(fs_info, EXTENT_TREE_V2)) {\n-\t\tbtrfs_err(fs_info, \"scrub is not supported on extent tree v2 yet\");\n+\t\tbtrfs_err(fs_info, \"scrub: extent tree v2 not yet supported\");\n \t\treturn -EINVAL;\n \t}\n \ndiff --git a/fs/btrfs/scrub.c b/fs/btrfs/scrub.c\nindex ce36fafc771e..7cd5e76a783c 100644\n--- a/fs/btrfs/scrub.c\n+++ b/fs/btrfs/scrub.c\n@@ -557,7 +557,7 @@ static int scrub_print_warning_inode(u64 inum, u64 offset, u64 num_bytes,\n \t */\n \tfor (i = 0; i < ipath->fspath->elem_cnt; ++i)\n \t\tbtrfs_warn_in_rcu(fs_info,\n-\"%s at logical %llu on dev %s, physical %llu, root %llu, inode %llu, offset %llu, length %u, links %u (path: %s)\",\n+\"scrub: %s at logical %llu on dev %s, physical %llu root %llu inode %llu offset %llu length %u links %u (path: %s)\",\n \t\t\t\t  swarn->errstr, swarn->logical,\n \t\t\t\t  btrfs_dev_name(swarn->dev),\n \t\t\t\t  swarn->physical,\n@@ -571,7 +571,7 @@ static int scrub_print_warning_inode(u64 inum, u64 offset, u64 num_bytes,\n \n err:\n \tbtrfs_warn_in_rcu(fs_info,\n-\t\t\t  \"%s at logical %llu on dev %s, physical %llu, root %llu, inode %llu, offset %llu: path resolving failed with ret=%d\",\n+\t\t\t  \"scrub: %s at logical %llu on dev %s, physical %llu root %llu inode %llu offset %llu: path resolving failed with ret=%d\",\n \t\t\t  swarn->errstr, swarn->logical,\n \t\t\t  btrfs_dev_name(swarn->dev),\n \t\t\t  swarn->physical,\n@@ -596,7 +596,7 @@ static void scrub_print_common_warning(const char *errstr, struct btrfs_device *\n \n \t/* Super block error, no need to search extent tree. */\n \tif (is_super) {\n-\t\tbtrfs_warn_in_rcu(fs_info, \"%s on device %s, physical %llu\",\n+\t\tbtrfs_warn_in_rcu(fs_info, \"scrub: %s on device %s, physical %llu\",\n \t\t\t\t  errstr, btrfs_dev_name(dev), physical);\n \t\treturn;\n \t}\n@@ -631,14 +631,14 @@ static void scrub_print_common_warning(const char *errstr, struct btrfs_device *\n \t\t\t\t\t\t      &ref_level);\n \t\t\tif (ret < 0) {\n \t\t\t\tbtrfs_warn(fs_info,\n-\t\t\t\t\"failed to resolve tree backref for logical %llu: %d\",\n-\t\t\t\t\t\t  swarn.logical, ret);\n+\t\t   \"scrub: failed to resolve tree backref for logical %llu: %d\",\n+\t\t\t\t\t   swarn.logical, ret);\n \t\t\t\tbreak;\n \t\t\t}\n \t\t\tif (ret > 0)\n \t\t\t\tbreak;\n \t\t\tbtrfs_warn_in_rcu(fs_info,\n-\"%s at logical %llu on dev %s, physical %llu: metadata %s (level %d) in tree %llu\",\n+\"scrub: %s at logical %llu on dev %s, physical %llu: metadata %s (level %d) in tree %llu\",\n \t\t\t\terrstr, swarn.logical, btrfs_dev_name(dev),\n \t\t\t\tswarn.physical, (ref_level ? \"node\" : \"leaf\"),\n \t\t\t\tref_level, ref_root);\n@@ -718,7 +718,7 @@ static void scrub_verify_one_metadata(struct scrub_stripe *stripe, int sector_nr\n \t\tscrub_bitmap_set_meta_error(stripe, sector_nr, sectors_per_tree);\n \t\tscrub_bitmap_set_error(stripe, sector_nr, sectors_per_tree);\n \t\tbtrfs_warn_rl(fs_info,\n-\t\t\"tree block %llu mirror %u has bad bytenr, has %llu want %llu\",\n+\t  \"scrub: tree block %llu mirror %u has bad bytenr, has %llu want %llu\",\n \t\t\t      logical, stripe->mirror_num,\n \t\t\t      btrfs_stack_header_bytenr(header), logical);\n \t\treturn;\n@@ -728,7 +728,7 @@ static void scrub_verify_one_metadata(struct scrub_stripe *stripe, int sector_nr\n \t\tscrub_bitmap_set_meta_error(stripe, sector_nr, sectors_per_tree);\n \t\tscrub_bitmap_set_error(stripe, sector_nr, sectors_per_tree);\n \t\tbtrfs_warn_rl(fs_info,\n-\t\t\"tree block %llu mirror %u has bad fsid, has %pU want %pU\",\n+\t      \"scrub: tree block %llu mirror %u has bad fsid, has %pU want %pU\",\n \t\t\t      logical, stripe->mirror_num,\n \t\t\t      header->fsid, fs_info->fs_devices->fsid);\n \t\treturn;\n@@ -738,7 +738,7 @@ static void scrub_verify_one_metadata(struct scrub_stripe *stripe, int sector_nr\n \t\tscrub_bitmap_set_meta_error(stripe, sector_nr, sectors_per_tree);\n \t\tscrub_bitmap_set_error(stripe, sector_nr, sectors_per_tree);\n \t\tbtrfs_warn_rl(fs_info,\n-\t\t\"tree block %llu mirror %u has bad chunk tree uuid, has %pU want %pU\",\n+   \"scrub: tree block %llu mirror %u has bad chunk tree uuid, has %pU want %pU\",\n \t\t\t      logical, stripe->mirror_num,\n \t\t\t      header->chunk_tree_uuid, fs_info->chunk_tree_uuid);\n \t\treturn;\n@@ -760,7 +760,7 @@ static void scrub_verify_one_metadata(struct scrub_stripe *stripe, int sector_nr\n \t\tscrub_bitmap_set_meta_error(stripe, sector_nr, sectors_per_tree);\n \t\tscrub_bitmap_set_error(stripe, sector_nr, sectors_per_tree);\n \t\tbtrfs_warn_rl(fs_info,\n-\t\t\"tree block %llu mirror %u has bad csum, has \" CSUM_FMT \" want \" CSUM_FMT,\n+\"scrub: tree block %llu mirror %u has bad csum, has \" CSUM_FMT \" want \" CSUM_FMT,\n \t\t\t      logical, stripe->mirror_num,\n \t\t\t      CSUM_FMT_VALUE(fs_info->csum_size, on_disk_csum),\n \t\t\t      CSUM_FMT_VALUE(fs_info->csum_size, calculated_csum));\n@@ -771,7 +771,7 @@ static void scrub_verify_one_metadata(struct scrub_stripe *stripe, int sector_nr\n \t\tscrub_bitmap_set_meta_gen_error(stripe, sector_nr, sectors_per_tree);\n \t\tscrub_bitmap_set_error(stripe, sector_nr, sectors_per_tree);\n \t\tbtrfs_warn_rl(fs_info,\n-\t\t\"tree block %llu mirror %u has bad generation, has %llu want %llu\",\n+      \"scrub: tree block %llu mirror %u has bad generation, has %llu want %llu\",\n \t\t\t      logical, stripe->mirror_num,\n \t\t\t      btrfs_stack_header_generation(header),\n \t\t\t      stripe->sectors[sector_nr].generation);\n@@ -814,7 +814,7 @@ static void scrub_verify_one_sector(struct scrub_stripe *stripe, int sector_nr)\n \t\t */\n \t\tif (unlikely(sector_nr + sectors_per_tree > stripe->nr_sectors)) {\n \t\t\tbtrfs_warn_rl(fs_info,\n-\t\t\t\"tree block at %llu crosses stripe boundary %llu\",\n+\t\t\t\"scrub: tree block at %llu crosses stripe boundary %llu\",\n \t\t\t\t      stripe->logical +\n \t\t\t\t      (sector_nr << fs_info->sectorsize_bits),\n \t\t\t\t      stripe->logical);\n@@ -1046,12 +1046,12 @@ static void scrub_stripe_report_errors(struct scrub_ctx *sctx,\n \t\tif (repaired) {\n \t\t\tif (dev) {\n \t\t\t\tbtrfs_err_rl_in_rcu(fs_info,\n-\t\t\t\"fixed up error at logical %llu on dev %s physical %llu\",\n+\t\t\"scrub: fixed up error at logical %llu on dev %s physical %llu\",\n \t\t\t\t\t    stripe->logical, btrfs_dev_name(dev),\n \t\t\t\t\t    physical);\n \t\t\t} else {\n \t\t\t\tbtrfs_err_rl_in_rcu(fs_info,\n-\t\t\t\"fixed up error at logical %llu on mirror %u\",\n+\t\t\t   \"scrub: fixed up error at logical %llu on mirror %u\",\n \t\t\t\t\t    stripe->logical, stripe->mirror_num);\n \t\t\t}\n \t\t\tcontinue;\n@@ -1060,12 +1060,12 @@ static void scrub_stripe_report_errors(struct scrub_ctx *sctx,\n \t\t/* The remaining are all for unrepaired. */\n \t\tif (dev) {\n \t\t\tbtrfs_err_rl_in_rcu(fs_info,\n-\t\"unable to fixup (regular) error at logical %llu on dev %s physical %llu\",\n+\"scrub: unable to fixup (regular) error at logical %llu on dev %s physical %llu\",\n \t\t\t\t\t    stripe->logical, btrfs_dev_name(dev),\n \t\t\t\t\t    physical);\n \t\t} else {\n \t\t\tbtrfs_err_rl_in_rcu(fs_info,\n-\t\"unable to fixup (regular) error at logical %llu on mirror %u\",\n+\t  \"scrub: unable to fixup (regular) error at logical %llu on mirror %u\",\n \t\t\t\t\t    stripe->logical, stripe->mirror_num);\n \t\t}\n \n@@ -1593,8 +1593,7 @@ static int sync_write_pointer_for_zoned(struct scrub_ctx *sctx, u64 logical,\n \t\t\t\t\t\t    physical,\n \t\t\t\t\t\t    sctx->write_pointer);\n \t\tif (ret)\n-\t\t\tbtrfs_err(fs_info,\n-\t\t\t\t  \"zoned: failed to recover write pointer\");\n+\t\t\tbtrfs_err(fs_info, \"scrub: zoned: failed to recover write pointer\");\n \t}\n \tmutex_unlock(&sctx->wr_lock);\n \tbtrfs_dev_clear_zone_empty(sctx->wr_tgtdev, physical);\n@@ -1658,7 +1657,7 @@ static int scrub_find_fill_first_stripe(struct btrfs_block_group *bg,\n \tint ret;\n \n \tif (unlikely(!extent_root || !csum_root)) {\n-\t\tbtrfs_err(fs_info, \"no valid extent or csum root for scrub\");\n+\t\tbtrfs_err(fs_info, \"scrub: no valid extent or csum root found\");\n \t\treturn -EUCLEAN;\n \t}\n \tmemset(stripe->sectors, 0, sizeof(struct scrub_sector_verification) *\n@@ -1907,7 +1906,7 @@ static bool stripe_has_metadata_error(struct scrub_stripe *stripe)\n \t\t\tstruct btrfs_fs_info *fs_info = stripe->bg->fs_info;\n \n \t\t\tbtrfs_err(fs_info,\n-\t\t\t\"stripe %llu has unrepaired metadata sector at %llu\",\n+\t\t    \"scrub: stripe %llu has unrepaired metadata sector at logical %llu\",\n \t\t\t\t  stripe->logical,\n \t\t\t\t  stripe->logical + (i << fs_info->sectorsize_bits));\n \t\t\treturn true;\n@@ -2167,7 +2166,7 @@ static int scrub_raid56_parity_stripe(struct scrub_ctx *sctx,\n \t\tbitmap_and(&error, &error, &has_extent, stripe->nr_sectors);\n \t\tif (!bitmap_empty(&error, stripe->nr_sectors)) {\n \t\t\tbtrfs_err(fs_info,\n-\"unrepaired sectors detected, full stripe %llu data stripe %u errors %*pbl\",\n+\"scrub: unrepaired sectors detected, full stripe %llu data stripe %u errors %*pbl\",\n \t\t\t\t  full_stripe_start, i, stripe->nr_sectors,\n \t\t\t\t  &error);\n \t\t\tret = -EIO;\n@@ -2789,14 +2788,14 @@ int scrub_enumerate_chunks(struct scrub_ctx *sctx,\n \t\t\tro_set = 0;\n \t\t} else if (ret == -ETXTBSY) {\n \t\t\tbtrfs_warn(fs_info,\n-\t\t   \"skipping scrub of block group %llu due to active swapfile\",\n+\t     \"scrub: skipping scrub of block group %llu due to active swapfile\",\n \t\t\t\t   cache->start);\n \t\t\tscrub_pause_off(fs_info);\n \t\t\tret = 0;\n \t\t\tgoto skip_unfreeze;\n \t\t} else {\n-\t\t\tbtrfs_warn(fs_info,\n-\t\t\t\t   \"failed setting block group ro: %d\", ret);\n+\t\t\tbtrfs_warn(fs_info, \"scrub: failed setting block group ro: %d\",\n+\t\t\t\t   ret);\n \t\t\tbtrfs_unfreeze_block_group(cache);\n \t\t\tbtrfs_put_block_group(cache);\n \t\t\tscrub_pause_off(fs_info);\n@@ -2892,13 +2891,13 @@ static int scrub_one_super(struct scrub_ctx *sctx, struct btrfs_device *dev,\n \tret = btrfs_check_super_csum(fs_info, sb);\n \tif (ret != 0) {\n \t\tbtrfs_err_rl(fs_info,\n-\t\t\t\"super block at physical %llu devid %llu has bad csum\",\n+\t\t  \"scrub: super block at physical %llu devid %llu has bad csum\",\n \t\t\tphysical, dev->devid);\n \t\treturn -EIO;\n \t}\n \tif (btrfs_super_generation(sb) != generation) {\n \t\tbtrfs_err_rl(fs_info,\n-\"super block at physical %llu devid %llu has bad generation %llu expect %llu\",\n+\"scrub: super block at physical %llu devid %llu has bad generation %llu expect %llu\",\n \t\t\t     physical, dev->devid,\n \t\t\t     btrfs_super_generation(sb), generation);\n \t\treturn -EUCLEAN;\n@@ -3059,7 +3058,7 @@ int btrfs_scrub_dev(struct btrfs_fs_info *fs_info, u64 devid, u64 start,\n \t    !test_bit(BTRFS_DEV_STATE_WRITEABLE, &dev->dev_state)) {\n \t\tmutex_unlock(&fs_info->fs_devices->device_list_mutex);\n \t\tbtrfs_err_in_rcu(fs_info,\n-\t\t\t\"scrub on devid %llu: filesystem on %s is not writable\",\n+\t\t\t\"scrub: devid %llu: filesystem on %s is not writable\",\n \t\t\t\t devid, btrfs_dev_name(dev));\n \t\tret = -EROFS;\n \t\tgoto out;\ndiff --git a/fs/btrfs/tree-log.c b/fs/btrfs/tree-log.c\nindex 97e933113b82..858b609e292c 100644\n--- a/fs/btrfs/tree-log.c\n+++ b/fs/btrfs/tree-log.c\n@@ -668,15 +668,15 @@ static noinline int replay_one_extent(struct btrfs_trans_handle *trans,\n \t\textent_end = ALIGN(start + size,\n \t\t\t\t   fs_info->sectorsize);\n \t} else {\n-\t\tret = 0;\n-\t\tgoto out;\n+\t\tbtrfs_err(fs_info,\n+\t\t  \"unexpected extent type=%d root=%llu inode=%llu offset=%llu\",\n+\t\t\t  found_type, btrfs_root_id(root), key->objectid, key->offset);\n+\t\treturn -EUCLEAN;\n \t}\n \n \tinode = read_one_inode(root, key->objectid);\n-\tif (!inode) {\n-\t\tret = -EIO;\n-\t\tgoto out;\n-\t}\n+\tif (!inode)\n+\t\treturn -EIO;\n \n \t/*\n \t * first check to see if we already have this extent in the\n@@ -961,7 +961,8 @@ static noinline int drop_one_dir_item(struct btrfs_trans_handle *trans,\n \tret = unlink_inode_for_log_replay(trans, dir, inode, &name);\n out:\n \tkfree(name.name);\n-\tiput(&inode->vfs_inode);\n+\tif (inode)\n+\t\tiput(&inode->vfs_inode);\n \treturn ret;\n }\n \n@@ -1176,8 +1177,8 @@ static inline int __add_inode_ref(struct btrfs_trans_handle *trans,\n \t\t\t\t\tret = unlink_inode_for_log_replay(trans,\n \t\t\t\t\t\t\tvictim_parent,\n \t\t\t\t\t\t\tinode, &victim_name);\n+\t\t\t\t\tiput(&victim_parent->vfs_inode);\n \t\t\t\t}\n-\t\t\t\tiput(&victim_parent->vfs_inode);\n \t\t\t\tkfree(victim_name.name);\n \t\t\t\tif (ret)\n \t\t\t\t\treturn ret;\ndiff --git a/fs/btrfs/volumes.c b/fs/btrfs/volumes.c\nindex 89835071cfea..f475b4b7c457 100644\n--- a/fs/btrfs/volumes.c\n+++ b/fs/btrfs/volumes.c\n@@ -3282,6 +3282,12 @@ int btrfs_remove_chunk(struct btrfs_trans_handle *trans, u64 chunk_offset)\n \t\t\t\t\tdevice->bytes_used - dev_extent_len);\n \t\t\tatomic64_add(dev_extent_len, &fs_info->free_chunk_space);\n \t\t\tbtrfs_clear_space_info_full(fs_info);\n+\n+\t\t\tif (list_empty(&device->post_commit_list)) {\n+\t\t\t\tlist_add_tail(&device->post_commit_list,\n+\t\t\t\t\t      &trans->transaction->dev_update_list);\n+\t\t\t}\n+\n \t\t\tmutex_unlock(&fs_info->chunk_mutex);\n \t\t}\n \t}\ndiff --git a/fs/btrfs/zoned.c b/fs/btrfs/zoned.c\nindex b5b0156d5b95..9430b34d3cbb 100644\n--- a/fs/btrfs/zoned.c\n+++ b/fs/btrfs/zoned.c\n@@ -1403,7 +1403,8 @@ static int btrfs_load_block_group_single(struct btrfs_block_group *bg,\n static int btrfs_load_block_group_dup(struct btrfs_block_group *bg,\n \t\t\t\t      struct btrfs_chunk_map *map,\n \t\t\t\t      struct zone_info *zone_info,\n-\t\t\t\t      unsigned long *active)\n+\t\t\t\t      unsigned long *active,\n+\t\t\t\t      u64 last_alloc)\n {\n \tstruct btrfs_fs_info *fs_info = bg->fs_info;\n \n@@ -1426,6 +1427,13 @@ static int btrfs_load_block_group_dup(struct btrfs_block_group *bg,\n \t\t\t  zone_info[1].physical);\n \t\treturn -EIO;\n \t}\n+\n+\tif (zone_info[0].alloc_offset == WP_CONVENTIONAL)\n+\t\tzone_info[0].alloc_offset = last_alloc;\n+\n+\tif (zone_info[1].alloc_offset == WP_CONVENTIONAL)\n+\t\tzone_info[1].alloc_offset = last_alloc;\n+\n \tif (zone_info[0].alloc_offset != zone_info[1].alloc_offset) {\n \t\tbtrfs_err(bg->fs_info,\n \t\t\t  \"zoned: write pointer offset mismatch of zones in DUP profile\");\n@@ -1446,7 +1454,8 @@ static int btrfs_load_block_group_dup(struct btrfs_block_group *bg,\n static int btrfs_load_block_group_raid1(struct btrfs_block_group *bg,\n \t\t\t\t\tstruct btrfs_chunk_map *map,\n \t\t\t\t\tstruct zone_info *zone_info,\n-\t\t\t\t\tunsigned long *active)\n+\t\t\t\t\tunsigned long *active,\n+\t\t\t\t\tu64 last_alloc)\n {\n \tstruct btrfs_fs_info *fs_info = bg->fs_info;\n \tint i;\n@@ -1461,10 +1470,12 @@ static int btrfs_load_block_group_raid1(struct btrfs_block_group *bg,\n \tbg->zone_capacity = min_not_zero(zone_info[0].capacity, zone_info[1].capacity);\n \n \tfor (i = 0; i < map->num_stripes; i++) {\n-\t\tif (zone_info[i].alloc_offset == WP_MISSING_DEV ||\n-\t\t    zone_info[i].alloc_offset == WP_CONVENTIONAL)\n+\t\tif (zone_info[i].alloc_offset == WP_MISSING_DEV)\n \t\t\tcontinue;\n \n+\t\tif (zone_info[i].alloc_offset == WP_CONVENTIONAL)\n+\t\t\tzone_info[i].alloc_offset = last_alloc;\n+\n \t\tif ((zone_info[0].alloc_offset != zone_info[i].alloc_offset) &&\n \t\t    !btrfs_test_opt(fs_info, DEGRADED)) {\n \t\t\tbtrfs_err(fs_info,\n@@ -1494,7 +1505,8 @@ static int btrfs_load_block_group_raid1(struct btrfs_block_group *bg,\n static int btrfs_load_block_group_raid0(struct btrfs_block_group *bg,\n \t\t\t\t\tstruct btrfs_chunk_map *map,\n \t\t\t\t\tstruct zone_info *zone_info,\n-\t\t\t\t\tunsigned long *active)\n+\t\t\t\t\tunsigned long *active,\n+\t\t\t\t\tu64 last_alloc)\n {\n \tstruct btrfs_fs_info *fs_info = bg->fs_info;\n \n@@ -1505,10 +1517,29 @@ static int btrfs_load_block_group_raid0(struct btrfs_block_group *bg,\n \t}\n \n \tfor (int i = 0; i < map->num_stripes; i++) {\n-\t\tif (zone_info[i].alloc_offset == WP_MISSING_DEV ||\n-\t\t    zone_info[i].alloc_offset == WP_CONVENTIONAL)\n+\t\tif (zone_info[i].alloc_offset == WP_MISSING_DEV)\n \t\t\tcontinue;\n \n+\t\tif (zone_info[i].alloc_offset == WP_CONVENTIONAL) {\n+\t\t\tu64 stripe_nr, full_stripe_nr;\n+\t\t\tu64 stripe_offset;\n+\t\t\tint stripe_index;\n+\n+\t\t\tstripe_nr = div64_u64(last_alloc, map->stripe_size);\n+\t\t\tstripe_offset = stripe_nr * map->stripe_size;\n+\t\t\tfull_stripe_nr = div_u64(stripe_nr, map->num_stripes);\n+\t\t\tdiv_u64_rem(stripe_nr, map->num_stripes, &stripe_index);\n+\n+\t\t\tzone_info[i].alloc_offset =\n+\t\t\t\tfull_stripe_nr * map->stripe_size;\n+\n+\t\t\tif (stripe_index > i)\n+\t\t\t\tzone_info[i].alloc_offset += map->stripe_size;\n+\t\t\telse if (stripe_index == i)\n+\t\t\t\tzone_info[i].alloc_offset +=\n+\t\t\t\t\t(last_alloc - stripe_offset);\n+\t\t}\n+\n \t\tif (test_bit(0, active) != test_bit(i, active)) {\n \t\t\tif (!btrfs_zone_activate(bg))\n \t\t\t\treturn -EIO;\n@@ -1526,7 +1557,8 @@ static int btrfs_load_block_group_raid0(struct btrfs_block_group *bg,\n static int btrfs_load_block_group_raid10(struct btrfs_block_group *bg,\n \t\t\t\t\t struct btrfs_chunk_map *map,\n \t\t\t\t\t struct zone_info *zone_info,\n-\t\t\t\t\t unsigned long *active)\n+\t\t\t\t\t unsigned long *active,\n+\t\t\t\t\t u64 last_alloc)\n {\n \tstruct btrfs_fs_info *fs_info = bg->fs_info;\n \n@@ -1537,8 +1569,7 @@ static int btrfs_load_block_group_raid10(struct btrfs_block_group *bg,\n \t}\n \n \tfor (int i = 0; i < map->num_stripes; i++) {\n-\t\tif (zone_info[i].alloc_offset == WP_MISSING_DEV ||\n-\t\t    zone_info[i].alloc_offset == WP_CONVENTIONAL)\n+\t\tif (zone_info[i].alloc_offset == WP_MISSING_DEV)\n \t\t\tcontinue;\n \n \t\tif (test_bit(0, active) != test_bit(i, active)) {\n@@ -1549,6 +1580,29 @@ static int btrfs_load_block_group_raid10(struct btrfs_block_group *bg,\n \t\t\t\tset_bit(BLOCK_GROUP_FLAG_ZONE_IS_ACTIVE, &bg->runtime_flags);\n \t\t}\n \n+\t\tif (zone_info[i].alloc_offset == WP_CONVENTIONAL) {\n+\t\t\tu64 stripe_nr, full_stripe_nr;\n+\t\t\tu64 stripe_offset;\n+\t\t\tint stripe_index;\n+\n+\t\t\tstripe_nr = div64_u64(last_alloc, map->stripe_size);\n+\t\t\tstripe_offset = stripe_nr * map->stripe_size;\n+\t\t\tfull_stripe_nr = div_u64(stripe_nr,\n+\t\t\t\t\t map->num_stripes / map->sub_stripes);\n+\t\t\tdiv_u64_rem(stripe_nr,\n+\t\t\t\t    (map->num_stripes / map->sub_stripes),\n+\t\t\t\t    &stripe_index);\n+\n+\t\t\tzone_info[i].alloc_offset =\n+\t\t\t\tfull_stripe_nr * map->stripe_size;\n+\n+\t\t\tif (stripe_index > (i / map->sub_stripes))\n+\t\t\t\tzone_info[i].alloc_offset += map->stripe_size;\n+\t\t\telse if (stripe_index == (i / map->sub_stripes))\n+\t\t\t\tzone_info[i].alloc_offset +=\n+\t\t\t\t\t(last_alloc - stripe_offset);\n+\t\t}\n+\n \t\tif ((i % map->sub_stripes) == 0) {\n \t\t\tbg->zone_capacity += zone_info[i].capacity;\n \t\t\tbg->alloc_offset += zone_info[i].alloc_offset;\n@@ -1637,18 +1691,22 @@ int btrfs_load_block_group_zone_info(struct btrfs_block_group *cache, bool new)\n \t\tret = btrfs_load_block_group_single(cache, &zone_info[0], active);\n \t\tbreak;\n \tcase BTRFS_BLOCK_GROUP_DUP:\n-\t\tret = btrfs_load_block_group_dup(cache, map, zone_info, active);\n+\t\tret = btrfs_load_block_group_dup(cache, map, zone_info, active,\n+\t\t\t\t\t\t last_alloc);\n \t\tbreak;\n \tcase BTRFS_BLOCK_GROUP_RAID1:\n \tcase BTRFS_BLOCK_GROUP_RAID1C3:\n \tcase BTRFS_BLOCK_GROUP_RAID1C4:\n-\t\tret = btrfs_load_block_group_raid1(cache, map, zone_info, active);\n+\t\tret = btrfs_load_block_group_raid1(cache, map, zone_info,\n+\t\t\t\t\t\t   active, last_alloc);\n \t\tbreak;\n \tcase BTRFS_BLOCK_GROUP_RAID0:\n-\t\tret = btrfs_load_block_group_raid0(cache, map, zone_info, active);\n+\t\tret = btrfs_load_block_group_raid0(cache, map, zone_info,\n+\t\t\t\t\t\t   active, last_alloc);\n \t\tbreak;\n \tcase BTRFS_BLOCK_GROUP_RAID10:\n-\t\tret = btrfs_load_block_group_raid10(cache, map, zone_info, active);\n+\t\tret = btrfs_load_block_group_raid10(cache, map, zone_info,\n+\t\t\t\t\t\t    active, last_alloc);\n \t\tbreak;\n \tcase BTRFS_BLOCK_GROUP_RAID5:\n \tcase BTRFS_BLOCK_GROUP_RAID6:",
    "stats": {
      "insertions": 219,
      "deletions": 82,
      "files": 10
    }
  },
  {
    "sha": "aa485e8789d56a4573f7c8d000a182b749eaa64d",
    "message": "libbpf: Fix null pointer dereference in btf_dump__free on allocation failure\n\nWhen btf_dump__new() fails to allocate memory for the internal hashmap\n(btf_dump->type_names), it returns an error code. However, the cleanup\nfunction btf_dump__free() does not check if btf_dump->type_names is NULL\nbefore attempting to free it. This leads to a null pointer dereference\nwhen btf_dump__free() is called on a btf_dump object.\n\nFixes: 351131b51c7a (\"libbpf: add btf_dump API for BTF-to-C conversion\")\nSigned-off-by: Yuan Chen <chenyuan@kylinos.cn>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20250618011933.11423-1-chenyuan_fl@163.com",
    "author": "Yuan Chen",
    "date": "2025-06-23T11:13:40-07:00",
    "files_changed": [
      "tools/lib/bpf/btf_dump.c"
    ],
    "diff": "diff --git a/tools/lib/bpf/btf_dump.c b/tools/lib/bpf/btf_dump.c\nindex 460c3e57fadb..0381f209920a 100644\n--- a/tools/lib/bpf/btf_dump.c\n+++ b/tools/lib/bpf/btf_dump.c\n@@ -226,6 +226,9 @@ static void btf_dump_free_names(struct hashmap *map)\n \tsize_t bkt;\n \tstruct hashmap_entry *cur;\n \n+\tif (!map)\n+\t\treturn;\n+\n \thashmap__for_each_entry(map, cur, bkt)\n \t\tfree((void *)cur->pkey);\n ",
    "stats": {
      "insertions": 3,
      "deletions": 0,
      "files": 1
    }
  }
]