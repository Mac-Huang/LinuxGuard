[
  {
    "sha": "f5769359c5b241978e6933672bb78b3adc36aa18",
    "message": "mm/alloc_tag: fix the kmemleak false positive issue in the allocation of the percpu variable tag->counters\n\nWhen loading a module, as long as the module has memory allocation\noperations, kmemleak produces a false positive report that resembles the\nfollowing:\n\nunreferenced object (percpu) 0x7dfd232a1650 (size 16):\n  comm \"modprobe\", pid 1301, jiffies 4294940249\n  hex dump (first 16 bytes on cpu 2):\n    00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................\n  backtrace (crc 0):\n    kmemleak_alloc_percpu+0xb4/0xd0\n    pcpu_alloc_noprof+0x700/0x1098\n    load_module+0xd4/0x348\n    codetag_module_init+0x20c/0x450\n    codetag_load_module+0x70/0xb8\n    load_module+0xef8/0x1608\n    init_module_from_file+0xec/0x158\n    idempotent_init_module+0x354/0x608\n    __arm64_sys_finit_module+0xbc/0x150\n    invoke_syscall+0xd4/0x258\n    el0_svc_common.constprop.0+0xb4/0x240\n    do_el0_svc+0x48/0x68\n    el0_svc+0x40/0xf8\n    el0t_64_sync_handler+0x10c/0x138\n    el0t_64_sync+0x1ac/0x1b0\n\nThis is because the module can only indirectly reference\nalloc_tag_counters through the alloc_tag section, which misleads kmemleak.\n\nHowever, we don't have a kmemleak ignore interface for percpu allocations\nyet.  So let's create one and invoke it for tag->counters.\n\n[gehao@kylinos.cn: fix build error when CONFIG_DEBUG_KMEMLEAK=n, s/igonore/ignore/]\n  Link: https://lkml.kernel.org/r/20250620093102.2416767-1-hao.ge@linux.dev\nLink: https://lkml.kernel.org/r/20250619183154.2122608-1-hao.ge@linux.dev\nFixes: 12ca42c23775 (\"alloc_tag: allocate percpu counters for module tags dynamically\")\nSigned-off-by: Hao Ge <gehao@kylinos.cn>\nReviewed-by: Catalin Marinas <catalin.marinas@arm.com>\nAcked-by: Suren Baghdasaryan <surenb@google.com>\t[lib/alloc_tag.c]\nCc: Kent Overstreet <kent.overstreet@linux.dev>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>",
    "author": "Hao Ge",
    "date": "2025-06-25T15:55:03-07:00",
    "files_changed": [
      "include/linux/kmemleak.h",
      "lib/alloc_tag.c",
      "mm/kmemleak.c"
    ],
    "diff": "diff --git a/include/linux/kmemleak.h b/include/linux/kmemleak.h\nindex 93a73c076d16..fbd424b2abb1 100644\n--- a/include/linux/kmemleak.h\n+++ b/include/linux/kmemleak.h\n@@ -28,6 +28,7 @@ extern void kmemleak_update_trace(const void *ptr) __ref;\n extern void kmemleak_not_leak(const void *ptr) __ref;\n extern void kmemleak_transient_leak(const void *ptr) __ref;\n extern void kmemleak_ignore(const void *ptr) __ref;\n+extern void kmemleak_ignore_percpu(const void __percpu *ptr) __ref;\n extern void kmemleak_scan_area(const void *ptr, size_t size, gfp_t gfp) __ref;\n extern void kmemleak_no_scan(const void *ptr) __ref;\n extern void kmemleak_alloc_phys(phys_addr_t phys, size_t size,\n@@ -97,6 +98,9 @@ static inline void kmemleak_not_leak(const void *ptr)\n static inline void kmemleak_transient_leak(const void *ptr)\n {\n }\n+static inline void kmemleak_ignore_percpu(const void __percpu *ptr)\n+{\n+}\n static inline void kmemleak_ignore(const void *ptr)\n {\n }\ndiff --git a/lib/alloc_tag.c b/lib/alloc_tag.c\nindex d48b80f3f007..3a74d63a959e 100644\n--- a/lib/alloc_tag.c\n+++ b/lib/alloc_tag.c\n@@ -10,6 +10,7 @@\n #include <linux/seq_buf.h>\n #include <linux/seq_file.h>\n #include <linux/vmalloc.h>\n+#include <linux/kmemleak.h>\n \n #define ALLOCINFO_FILE_NAME\t\t\"allocinfo\"\n #define MODULE_ALLOC_TAG_VMAP_SIZE\t(100000UL * sizeof(struct alloc_tag))\n@@ -632,8 +633,13 @@ static int load_module(struct module *mod, struct codetag *start, struct codetag\n \t\t\t       mod->name);\n \t\t\treturn -ENOMEM;\n \t\t}\n-\t}\n \n+\t\t/*\n+\t\t * Avoid a kmemleak false positive. The pointer to the counters is stored\n+\t\t * in the alloc_tag section of the module and cannot be directly accessed.\n+\t\t */\n+\t\tkmemleak_ignore_percpu(tag->counters);\n+\t}\n \treturn 0;\n }\n \ndiff --git a/mm/kmemleak.c b/mm/kmemleak.c\nindex da9cee34ee1b..8d588e685311 100644\n--- a/mm/kmemleak.c\n+++ b/mm/kmemleak.c\n@@ -1246,6 +1246,20 @@ void __ref kmemleak_transient_leak(const void *ptr)\n }\n EXPORT_SYMBOL(kmemleak_transient_leak);\n \n+/**\n+ * kmemleak_ignore_percpu - similar to kmemleak_ignore but taking a percpu\n+ *\t\t\t    address argument\n+ * @ptr:\tpercpu address of the object\n+ */\n+void __ref kmemleak_ignore_percpu(const void __percpu *ptr)\n+{\n+\tpr_debug(\"%s(0x%px)\\n\", __func__, ptr);\n+\n+\tif (kmemleak_enabled && ptr && !IS_ERR_PCPU(ptr))\n+\t\tmake_black_object((unsigned long)ptr, OBJECT_PERCPU);\n+}\n+EXPORT_SYMBOL_GPL(kmemleak_ignore_percpu);\n+\n /**\n  * kmemleak_ignore - ignore an allocated object\n  * @ptr:\tpointer to beginning of the object",
    "stats": {
      "insertions": 25,
      "deletions": 1,
      "files": 3
    }
  },
  {
    "sha": "df831e97739405ecbaddb85516bc7d4d1c933d6b",
    "message": "lib/group_cpus: fix NULL pointer dereference from group_cpus_evenly()\n\nWhile testing null_blk with configfs, echo 0 > poll_queues will trigger\nfollowing panic:\n\nBUG: kernel NULL pointer dereference, address: 0000000000000010\nOops: Oops: 0000 [#1] SMP NOPTI\nCPU: 27 UID: 0 PID: 920 Comm: bash Not tainted 6.15.0-02023-gadbdb95c8696-dirty #1238 PREEMPT(undef)\nHardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.16.1-2.fc37 04/01/2014\nRIP: 0010:__bitmap_or+0x48/0x70\nCall Trace:\n <TASK>\n __group_cpus_evenly+0x822/0x8c0\n group_cpus_evenly+0x2d9/0x490\n blk_mq_map_queues+0x1e/0x110\n null_map_queues+0xc9/0x170 [null_blk]\n blk_mq_update_queue_map+0xdb/0x160\n blk_mq_update_nr_hw_queues+0x22b/0x560\n nullb_update_nr_hw_queues+0x71/0xf0 [null_blk]\n nullb_device_poll_queues_store+0xa4/0x130 [null_blk]\n configfs_write_iter+0x109/0x1d0\n vfs_write+0x26e/0x6f0\n ksys_write+0x79/0x180\n __x64_sys_write+0x1d/0x30\n x64_sys_call+0x45c4/0x45f0\n do_syscall_64+0xa5/0x240\n entry_SYSCALL_64_after_hwframe+0x76/0x7e\n\nRoot cause is that numgrps is set to 0, and ZERO_SIZE_PTR is returned from\nkcalloc(), and later ZERO_SIZE_PTR will be deferenced.\n\nFix the problem by checking numgrps first in group_cpus_evenly(), and\nreturn NULL directly if numgrps is zero.\n\n[yukuai3@huawei.com: also fix the non-SMP version]\n  Link: https://lkml.kernel.org/r/20250620010958.1265984-1-yukuai1@huaweicloud.com\nLink: https://lkml.kernel.org/r/20250619132655.3318883-1-yukuai1@huaweicloud.com\nFixes: 6a6dcae8f486 (\"blk-mq: Build default queue map via group_cpus_evenly()\")\nSigned-off-by: Yu Kuai <yukuai3@huawei.com>\nReviewed-by: Ming Lei <ming.lei@redhat.com>\nReviewed-by: Jens Axboe <axboe@kernel.dk>\nCc: ErKun Yang <yangerkun@huawei.com>\nCc: John Garry <john.g.garry@oracle.com>\nCc: Thomas Gleinxer <tglx@linutronix.de>\nCc: \"zhangyi (F)\" <yi.zhang@huawei.com>\nCc: <stable@vger.kernel.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>",
    "author": "Yu Kuai",
    "date": "2025-06-25T15:55:03-07:00",
    "files_changed": [
      "lib/group_cpus.c"
    ],
    "diff": "diff --git a/lib/group_cpus.c b/lib/group_cpus.c\nindex ee272c4cefcc..18d43a406114 100644\n--- a/lib/group_cpus.c\n+++ b/lib/group_cpus.c\n@@ -352,6 +352,9 @@ struct cpumask *group_cpus_evenly(unsigned int numgrps)\n \tint ret = -ENOMEM;\n \tstruct cpumask *masks = NULL;\n \n+\tif (numgrps == 0)\n+\t\treturn NULL;\n+\n \tif (!zalloc_cpumask_var(&nmsk, GFP_KERNEL))\n \t\treturn NULL;\n \n@@ -426,8 +429,12 @@ struct cpumask *group_cpus_evenly(unsigned int numgrps)\n #else /* CONFIG_SMP */\n struct cpumask *group_cpus_evenly(unsigned int numgrps)\n {\n-\tstruct cpumask *masks = kcalloc(numgrps, sizeof(*masks), GFP_KERNEL);\n+\tstruct cpumask *masks;\n \n+\tif (numgrps == 0)\n+\t\treturn NULL;\n+\n+\tmasks = kcalloc(numgrps, sizeof(*masks), GFP_KERNEL);\n \tif (!masks)\n \t\treturn NULL;\n ",
    "stats": {
      "insertions": 8,
      "deletions": 1,
      "files": 1
    }
  },
  {
    "sha": "344ef45b03336e7f74658814f66483b5417c9cf1",
    "message": "mm/hugetlb: remove unnecessary holding of hugetlb_lock\n\nIn isolate_or_dissolve_huge_folio(), after acquiring the hugetlb_lock, it\nis only for the purpose of obtaining the correct hstate, which is then\npassed to alloc_and_dissolve_hugetlb_folio().\n\nalloc_and_dissolve_hugetlb_folio() itself also acquires the hugetlb_lock. \nWe can have alloc_and_dissolve_hugetlb_folio() obtain the hstate by\nitself, so that isolate_or_dissolve_huge_folio() no longer needs to\nacquire the hugetlb_lock.  In addition, we keep the folio_test_hugetlb()\ncheck within isolate_or_dissolve_huge_folio().  By doing so, we can avoid\ndisrupting the normal path by vainly holding the hugetlb_lock.\n\nreplace_free_hugepage_folios() has the same issue, and we should address\nit as well.\n\nAddresses a possible performance problem which was added by the hotfix\n113ed54ad276 (\"mm/hugetlb: fix kernel NULL pointer dereference when\nreplacing free hugetlb folios\").\n\nLink: https://lkml.kernel.org/r/1748317010-16272-1-git-send-email-yangge1116@126.com\nFixes: 113ed54ad276 (\"mm/hugetlb: fix kernel NULL pointer dereference when replacing free hugetlb folios\")\nSigned-off-by: Ge Yang <yangge1116@126.com>\nSuggested-by: Oscar Salvador <osalvador@suse.de>\nReviewed-by: Muchun Song <muchun.song@linux.dev>\nCc: Baolin Wang <baolin.wang@linux.alibaba.com>\nCc: Barry Song <21cnbao@gmail.com>\nCc: David Hildenbrand <david@redhat.com>\nCc: <stable@vger.kernel.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>",
    "author": "Ge Yang",
    "date": "2025-06-25T15:55:03-07:00",
    "files_changed": [
      "mm/hugetlb.c"
    ],
    "diff": "diff --git a/mm/hugetlb.c b/mm/hugetlb.c\nindex 8746ed2fec13..9dc95eac558c 100644\n--- a/mm/hugetlb.c\n+++ b/mm/hugetlb.c\n@@ -2787,20 +2787,24 @@ void restore_reserve_on_error(struct hstate *h, struct vm_area_struct *vma,\n /*\n  * alloc_and_dissolve_hugetlb_folio - Allocate a new folio and dissolve\n  * the old one\n- * @h: struct hstate old page belongs to\n  * @old_folio: Old folio to dissolve\n  * @list: List to isolate the page in case we need to\n  * Returns 0 on success, otherwise negated error.\n  */\n-static int alloc_and_dissolve_hugetlb_folio(struct hstate *h,\n-\t\t\tstruct folio *old_folio, struct list_head *list)\n+static int alloc_and_dissolve_hugetlb_folio(struct folio *old_folio,\n+\t\t\tstruct list_head *list)\n {\n-\tgfp_t gfp_mask = htlb_alloc_mask(h) | __GFP_THISNODE;\n+\tgfp_t gfp_mask;\n+\tstruct hstate *h;\n \tint nid = folio_nid(old_folio);\n \tstruct folio *new_folio = NULL;\n \tint ret = 0;\n \n retry:\n+\t/*\n+\t * The old_folio might have been dissolved from under our feet, so make sure\n+\t * to carefully check the state under the lock.\n+\t */\n \tspin_lock_irq(&hugetlb_lock);\n \tif (!folio_test_hugetlb(old_folio)) {\n \t\t/*\n@@ -2829,8 +2833,10 @@ static int alloc_and_dissolve_hugetlb_folio(struct hstate *h,\n \t\tcond_resched();\n \t\tgoto retry;\n \t} else {\n+\t\th = folio_hstate(old_folio);\n \t\tif (!new_folio) {\n \t\t\tspin_unlock_irq(&hugetlb_lock);\n+\t\t\tgfp_mask = htlb_alloc_mask(h) | __GFP_THISNODE;\n \t\t\tnew_folio = alloc_buddy_hugetlb_folio(h, gfp_mask, nid,\n \t\t\t\t\t\t\t      NULL, NULL);\n \t\t\tif (!new_folio)\n@@ -2874,35 +2880,24 @@ static int alloc_and_dissolve_hugetlb_folio(struct hstate *h,\n \n int isolate_or_dissolve_huge_folio(struct folio *folio, struct list_head *list)\n {\n-\tstruct hstate *h;\n \tint ret = -EBUSY;\n \n-\t/*\n-\t * The page might have been dissolved from under our feet, so make sure\n-\t * to carefully check the state under the lock.\n-\t * Return success when racing as if we dissolved the page ourselves.\n-\t */\n-\tspin_lock_irq(&hugetlb_lock);\n-\tif (folio_test_hugetlb(folio)) {\n-\t\th = folio_hstate(folio);\n-\t} else {\n-\t\tspin_unlock_irq(&hugetlb_lock);\n+\t/* Not to disrupt normal path by vainly holding hugetlb_lock */\n+\tif (!folio_test_hugetlb(folio))\n \t\treturn 0;\n-\t}\n-\tspin_unlock_irq(&hugetlb_lock);\n \n \t/*\n \t * Fence off gigantic pages as there is a cyclic dependency between\n \t * alloc_contig_range and them. Return -ENOMEM as this has the effect\n \t * of bailing out right away without further retrying.\n \t */\n-\tif (hstate_is_gigantic(h))\n+\tif (folio_order(folio) > MAX_PAGE_ORDER)\n \t\treturn -ENOMEM;\n \n \tif (folio_ref_count(folio) && folio_isolate_hugetlb(folio, list))\n \t\tret = 0;\n \telse if (!folio_ref_count(folio))\n-\t\tret = alloc_and_dissolve_hugetlb_folio(h, folio, list);\n+\t\tret = alloc_and_dissolve_hugetlb_folio(folio, list);\n \n \treturn ret;\n }\n@@ -2916,7 +2911,6 @@ int isolate_or_dissolve_huge_folio(struct folio *folio, struct list_head *list)\n  */\n int replace_free_hugepage_folios(unsigned long start_pfn, unsigned long end_pfn)\n {\n-\tstruct hstate *h;\n \tstruct folio *folio;\n \tint ret = 0;\n \n@@ -2925,23 +2919,9 @@ int replace_free_hugepage_folios(unsigned long start_pfn, unsigned long end_pfn)\n \twhile (start_pfn < end_pfn) {\n \t\tfolio = pfn_folio(start_pfn);\n \n-\t\t/*\n-\t\t * The folio might have been dissolved from under our feet, so make sure\n-\t\t * to carefully check the state under the lock.\n-\t\t */\n-\t\tspin_lock_irq(&hugetlb_lock);\n-\t\tif (folio_test_hugetlb(folio)) {\n-\t\t\th = folio_hstate(folio);\n-\t\t} else {\n-\t\t\tspin_unlock_irq(&hugetlb_lock);\n-\t\t\tstart_pfn++;\n-\t\t\tcontinue;\n-\t\t}\n-\t\tspin_unlock_irq(&hugetlb_lock);\n-\n-\t\tif (!folio_ref_count(folio)) {\n-\t\t\tret = alloc_and_dissolve_hugetlb_folio(h, folio,\n-\t\t\t\t\t\t\t       &isolate_list);\n+\t\t/* Not to disrupt normal path by vainly holding hugetlb_lock */\n+\t\tif (folio_test_hugetlb(folio) && !folio_ref_count(folio)) {\n+\t\t\tret = alloc_and_dissolve_hugetlb_folio(folio, &isolate_list);\n \t\t\tif (ret)\n \t\t\t\tbreak;\n ",
    "stats": {
      "insertions": 17,
      "deletions": 37,
      "files": 1
    }
  },
  {
    "sha": "666c23af755dccca8c25b5d5200ca28153c69a05",
    "message": "i2c: omap: Fix an error handling path in omap_i2c_probe()\n\nIf an error occurs after calling mux_state_select(), mux_state_deselect()\nshould be called as already done in the remove function.\n\nFixes: b6ef830c60b6 (\"i2c: omap: Add support for setting mux\")\nSigned-off-by: Christophe JAILLET <christophe.jaillet@wanadoo.fr>\nCc: <stable@vger.kernel.org> # v6.15+\nSigned-off-by: Andi Shyti <andi.shyti@kernel.org>\nLink: https://lore.kernel.org/r/998542981b6d2435c057dd8b9fe71743927babab.1749913149.git.christophe.jaillet@wanadoo.fr",
    "author": "Christophe JAILLET",
    "date": "2025-06-26T00:07:33+02:00",
    "files_changed": [
      "drivers/i2c/busses/i2c-omap.c"
    ],
    "diff": "diff --git a/drivers/i2c/busses/i2c-omap.c b/drivers/i2c/busses/i2c-omap.c\nindex f1cc26ac5b80..8b01df3cc8e9 100644\n--- a/drivers/i2c/busses/i2c-omap.c\n+++ b/drivers/i2c/busses/i2c-omap.c\n@@ -1461,13 +1461,13 @@ omap_i2c_probe(struct platform_device *pdev)\n \t\tif (IS_ERR(mux_state)) {\n \t\t\tr = PTR_ERR(mux_state);\n \t\t\tdev_dbg(&pdev->dev, \"failed to get I2C mux: %d\\n\", r);\n-\t\t\tgoto err_disable_pm;\n+\t\t\tgoto err_put_pm;\n \t\t}\n \t\tomap->mux_state = mux_state;\n \t\tr = mux_state_select(omap->mux_state);\n \t\tif (r) {\n \t\t\tdev_err(&pdev->dev, \"failed to select I2C mux: %d\\n\", r);\n-\t\t\tgoto err_disable_pm;\n+\t\t\tgoto err_put_pm;\n \t\t}\n \t}\n \n@@ -1515,6 +1515,9 @@ omap_i2c_probe(struct platform_device *pdev)\n \n err_unuse_clocks:\n \tomap_i2c_write_reg(omap, OMAP_I2C_CON_REG, 0);\n+\tif (omap->mux_state)\n+\t\tmux_state_deselect(omap->mux_state);\n+err_put_pm:\n \tpm_runtime_dont_use_autosuspend(omap->dev);\n \tpm_runtime_put_sync(omap->dev);\n err_disable_pm:",
    "stats": {
      "insertions": 5,
      "deletions": 2,
      "files": 1
    }
  },
  {
    "sha": "fa6f092cc0a02d0fcee37e9e8172eda372a03d33",
    "message": "libbpf: Fix possible use-after-free for externs\n\nThe `name` field in `obj->externs` points into the BTF data at initial\nopen time. However, some functions may invalidate this after opening and\nbefore loading (e.g. `bpf_map__set_value_size`), which results in\npointers into freed memory and undefined behavior.\n\nThe simplest solution is to simply `strdup` these strings, similar to\nthe `essent_name`, and free them at the same time.\n\nIn order to test this path, the `global_map_resize` BPF selftest is\nmodified slightly to ensure the presence of an extern, which causes this\ntest to fail prior to the fix. Given there isn't an obvious API or error\nto test against, I opted to add this to the existing test as an aspect\nof the resizing feature rather than duplicate the test.\n\nFixes: 9d0a23313b1a (\"libbpf: Add capability for resizing datasec maps\")\nSigned-off-by: Adin Scannell <amscanne@meta.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20250625050215.2777374-1-amscanne@meta.com",
    "author": "Adin Scannell",
    "date": "2025-06-25T12:28:58-07:00",
    "files_changed": [
      "tools/lib/bpf/libbpf.c",
      "tools/testing/selftests/bpf/progs/test_global_map_resize.c"
    ],
    "diff": "diff --git a/tools/lib/bpf/libbpf.c b/tools/lib/bpf/libbpf.c\nindex e9c641a2fb20..52e353368f58 100644\n--- a/tools/lib/bpf/libbpf.c\n+++ b/tools/lib/bpf/libbpf.c\n@@ -597,7 +597,7 @@ struct extern_desc {\n \tint sym_idx;\n \tint btf_id;\n \tint sec_btf_id;\n-\tconst char *name;\n+\tchar *name;\n \tchar *essent_name;\n \tbool is_set;\n \tbool is_weak;\n@@ -4259,7 +4259,9 @@ static int bpf_object__collect_externs(struct bpf_object *obj)\n \t\t\treturn ext->btf_id;\n \t\t}\n \t\tt = btf__type_by_id(obj->btf, ext->btf_id);\n-\t\text->name = btf__name_by_offset(obj->btf, t->name_off);\n+\t\text->name = strdup(btf__name_by_offset(obj->btf, t->name_off));\n+\t\tif (!ext->name)\n+\t\t\treturn -ENOMEM;\n \t\text->sym_idx = i;\n \t\text->is_weak = ELF64_ST_BIND(sym->st_info) == STB_WEAK;\n \n@@ -9138,8 +9140,10 @@ void bpf_object__close(struct bpf_object *obj)\n \tzfree(&obj->btf_custom_path);\n \tzfree(&obj->kconfig);\n \n-\tfor (i = 0; i < obj->nr_extern; i++)\n+\tfor (i = 0; i < obj->nr_extern; i++) {\n+\t\tzfree(&obj->externs[i].name);\n \t\tzfree(&obj->externs[i].essent_name);\n+\t}\n \n \tzfree(&obj->externs);\n \tobj->nr_extern = 0;\ndiff --git a/tools/testing/selftests/bpf/progs/test_global_map_resize.c b/tools/testing/selftests/bpf/progs/test_global_map_resize.c\nindex a3f220ba7025..ee65bad0436d 100644\n--- a/tools/testing/selftests/bpf/progs/test_global_map_resize.c\n+++ b/tools/testing/selftests/bpf/progs/test_global_map_resize.c\n@@ -32,6 +32,16 @@ int my_int_last SEC(\".data.array_not_last\");\n \n int percpu_arr[1] SEC(\".data.percpu_arr\");\n \n+/* at least one extern is included, to ensure that a specific\n+ * regression is tested whereby resizing resulted in a free-after-use\n+ * bug after type information is invalidated by the resize operation.\n+ *\n+ * There isn't a particularly good API to test for this specific condition,\n+ * but by having externs for the resizing tests it will cover this path.\n+ */\n+extern int LINUX_KERNEL_VERSION __kconfig;\n+long version_sink;\n+\n SEC(\"tp/syscalls/sys_enter_getpid\")\n int bss_array_sum(void *ctx)\n {\n@@ -44,6 +54,9 @@ int bss_array_sum(void *ctx)\n \tfor (size_t i = 0; i < bss_array_len; ++i)\n \t\tsum += array[i];\n \n+\t/* see above; ensure this is not optimized out */\n+\tversion_sink = LINUX_KERNEL_VERSION;\n+\n \treturn 0;\n }\n \n@@ -59,6 +72,9 @@ int data_array_sum(void *ctx)\n \tfor (size_t i = 0; i < data_array_len; ++i)\n \t\tsum += my_array[i];\n \n+\t/* see above; ensure this is not optimized out */\n+\tversion_sink = LINUX_KERNEL_VERSION;\n+\n \treturn 0;\n }\n ",
    "stats": {
      "insertions": 23,
      "deletions": 3,
      "files": 2
    }
  }
]